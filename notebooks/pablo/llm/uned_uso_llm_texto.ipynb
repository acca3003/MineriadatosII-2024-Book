{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5c5df06-6d86-4786-817f-c1ae88605fdf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Ejemplo prompting para usar arquitectura zero-shot empleando LLMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d2d164c-97cf-4be6-b0eb-6081241649b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from loguru import logger\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "from requests.exceptions import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a928d6d1-2e17-474e-bd3c-dcce2fa7c452",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt = [\n",
    "    \"SYSTEM: Eres un asistente que analiza un texto y devuelve la temática de dicho texto\\n\\n\",\n",
    "    \"USER: A partir de esta cuestión {business_question}, devuelve una de las siguientes categorías: 'Otro', 'Deporte', 'Finanzas', 'Informática', 'Cine' \\n\\n\",\n",
    "    \"INSTRUCTIONS: \\n\\n\",\n",
    "    \"Presta atención a la cuestión y a las temáticas planteadas. Devuelve solo una única temática\\n\\n\",\n",
    "    \"Ejemplo 1 de uso\\n\\n\",\n",
    "    \"Pregunta: Las acciones del Santander han bajado un 2% en los últimos tres meses\",\n",
    "    \"Respuesta: Finanzas\\n\\n\",\n",
    "    \"Ejemplo 2 de uso\\n\\n\",\n",
    "    \"Pregunta: ¿España ganará la Eurocopa este año?\",\n",
    "    \"Respuesta: Deporte\\n\\n\",\n",
    "    \"Pregunta: Soy un enamorado de python\",\n",
    "    \"Respuesta: Informática\\n\\n\",\n",
    "    \"Pregunta: El Señor de los Anillos es una película que está sobrevalorada\",\n",
    "    \"Respuesta: Cine\\n\\n\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87d7f08a-91b3-4a44-b504-f75be638fdc0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _call_llm_model(\n",
    "    prompt: str, model_name: str = \"paa-gpt-4o-v20240513-dedicado-analitica\"\n",
    "    ) -> str:\n",
    "    \"\"\"\n",
    "    Función que llama al modelo LLM para hacer una predicción a partir de un prompt\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Mensaje del prompt\n",
    "\n",
    "    Returns:\n",
    "        response (str): Respuesta del modelo si no hay fallo en la conexión.\n",
    "        En otro caso, devuelve el mensaje de error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = get_deploy_client(\"databricks\")\n",
    "        response = client.predict(\n",
    "            endpoint=model_name,\n",
    "            inputs={\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "        )\n",
    "        response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        logger.info(\"Ejecución del LLM realizada\")\n",
    "    except HTTPError as e:\n",
    "        if e.response.text:\n",
    "            logger.info(f\"{e}. Response text: {e.response.text}\")\n",
    "        else:\n",
    "            logger.info(e)\n",
    "        response = e\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb2a941b-5e07-40c9-977a-bd59c8cab70c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _add_business_question_prompt(prompt: str, business_question: str) -> str:\n",
    "  \"\"\"\n",
    "  Función que añade al prompt la cuestión de negocio\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Mensaje del prompt\n",
    "        business_question (str): Pregunta de negocio a clasificar\n",
    "\n",
    "    Returns:\n",
    "        response (str): Respuesta del modelo si no hay fallo en la conexión.\n",
    "        En otro caso, devuelve el mensaje de error\n",
    "  \"\"\"\n",
    "  prompt_end = \" \".join(prompt)\n",
    "  prompt_end = prompt_end.replace(\"{business_question}\", business_question)\n",
    "  return prompt_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d296e15-b8d4-4c23-90e8-19edefe468c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Ejemplo de uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d742b53-907b-4118-a97f-2cc5fa3e01da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-28 20:24:01.574\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_call_llm_model\u001B[0m:\u001B[36m21\u001B[0m - \u001B[1mEjecución del LLM realizada\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Otro'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_question = \"Soy fanático de El Quijote\"\n",
    "prompt_end = _add_business_question_prompt(prompt, business_question)\n",
    "_call_llm_model(prompt_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdba7bde-ac4f-4f29-aad0-2149c7eb5300",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-28 20:24:02.673\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_call_llm_model\u001B[0m:\u001B[36m21\u001B[0m - \u001B[1mEjecución del LLM realizada\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Deporte'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_question = \"El Madrid ganó la última Champions\"\n",
    "prompt_end = _add_business_question_prompt(prompt, business_question)\n",
    "_call_llm_model(prompt_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bad0f67e-85d8-4c07-a6bc-08ef5939d598",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-28 20:24:03.035\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_call_llm_model\u001B[0m:\u001B[36m21\u001B[0m - \u001B[1mEjecución del LLM realizada\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Cine'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_question = \"Me encanta ver la televisión por la noche\"\n",
    "prompt_end = _add_business_question_prompt(prompt, business_question)\n",
    "_call_llm_model(prompt_end)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "uned_uso_llm_texto",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
