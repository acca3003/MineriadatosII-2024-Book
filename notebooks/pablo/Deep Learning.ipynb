{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e365d8c-7132-46d5-9457-8b8848a7283a",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e0a92-98f0-4fed-906f-dcd158977baf",
   "metadata": {},
   "source": [
    "El **deep learning**, también conocido como aprendizaje profundo**, es una disciplina que busca emular el funcionamiento del cerebro mediante el uso de hardware y software, generando inteligencia artificial. Este enfoque se materializa en redes neuronales artificiales (RNA), que emplean una abstracción jerárquica para representar datos en múltiples niveles. El proceso implica la utilización de arquitecturas de varias capas, donde cada una aprende patrones más complejos, favoreciendo el aprendizaje útil. Generalmente, se emplea aprendizaje no supervisado para guiar el entrenamiento de las capas intermedias. Aunque derivado del machine learning, el deep learning se distingue por su arquitectura en capas, inCluyendo redes convolucionales y recurrentes, en contraste con métodos más simples como el Perceptrón Multicapa de una sola capa. Su avance se vio inicialmente obstaculizado por problemas de estancamiento en mínimos locales, resueltos mediante preentrenamiento no supervisado de las capas. Este enfoque ha impulsado un rápido crecimiento en el desarrollo de arquitecturas y algoritmos de RNA en los últimos años, manteniendo la esencia del aprendizaje jerárquico y profundo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cbe31a-cbee-4ea2-be40-ff9e2e10e96a",
   "metadata": {},
   "source": [
    "Las redes neuronales tienen una amplia gama de aplicaciones en diversos campos, desde la clasificación y regresión de datos hasta la identificación de imágenes, texto y audio. \n",
    "\n",
    "En la *identificación de imágenes*, por ejemplo, pueden reconocer animales, señales de tráfico, frutas, caras humanas e incluso tumores malignos en radiografías. A medida que se combinan estas capacidades, se pueden abordar problemas más complejos como la detección de objetos y personas en imágenes o el etiquetado de escenas. Con el *análisis de videos*, las redes neuronales pueden contar personas, reconocer objetos y señales de tráfico, o detectar comportamientos como llevar un arma.\n",
    "\n",
    "Cuando se trata de *datos de texto*, las redes neuronales se utilizan en sistemas de traducción, chatbots y conversión de texto a audio. En el caso de *datos de audio*, se emplean en sistemas de traducción, altavoces inteligentes y conversión de audio a texto.\n",
    "\n",
    "Para **trabajar con redes neuronales**, es crucial representar los datos de entrada numéricamente, incluso convirtiendo variables categóricas en valores numéricos y normalizando los datos entre 0 y 1. Esto facilita la convergencia hacia soluciones óptimas. \n",
    "Es importante que los datos seán números en coma flotante, sobre todo si se van a trabajar con *GPUs, Graphics Process Units*, ya que permitirán hacer un mejor uso de los multiples cores que les permiten operar en coma flotante de forma paralela. Actualmente, hay toda una serie de mejoras en las GPUs que permite aumentar el rendimiento de las redes neuronales como son el uso de operaciones en *FP16* (Floating Point de 16 bits en lugar de 32) de forma que pueden hacer dos operaciones de forma simultánea (el formato estándar es FP32) y además con la reducción de memoria (punto muy importante) al meter en los 32 bits 2 datos en lugar de sólo uno. También se han añadido técnicas de *Mixed Precision* (Narang et al. 2018), los *Tensor Cores* (para las gráficas de NVIDIA) son otra de las mejoras que se han ido incorporando a la GPUs y que permiten acelerar los procesos tanto de entrenamiento como de predicción con las redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479917ba-7e6b-4909-8ba7-49ca7a3cf849",
   "metadata": {},
   "source": [
    "## Principales arquitecturas y software utilizado\n",
    "\n",
    "### Principales arquitecturas\n",
    "\n",
    "Actualmente existen muchos tipos de estructuras de redes neuronales artificiales dado que logran resultados extraordinarios en muchos campos del conocimiento. Los primeros éxitos en el aprendizaje profundo se lograron a través de las investigaciones y trabajos de Geoffre Hinton (2006) que introduce las Redes de Creencia Profunda en cada capa de la red de una Máquina de Boltzmann Restringida (RBM) para la asignación inicial de los pesos sinápticos.\n",
    "Hace tiempo que se está trabajando con arquitecturas como los Autoencoders, Hinton y Zemel (1994), las RBMs de Hinton y Sejnowski (1986) y las DBNs (Deep Belief Networks), Hinton et al. (2006) y otras como las redes recurrentes y convolucionales. Estas técnicas constituyen en sí mismas arquitecturas de redes neuronales, aunque también algunas de ellas, como se ha afirmado en la introducción, se están empleando para inicializar los pesos de arquitecturas profundas de redes neuronales supervisadas con conexiones hacia adelante.\n",
    "\n",
    "**Redes Convolucionales**\n",
    "\n",
    "Las redes neuronales convolucionales (CNNs) han transformado el panorama del Deep Learning, destacándose por su habilidad para extraer características de alto nivel a través de la operación de convolución. Diseñadas específicamente para el procesamiento de imágenes, las CNNs son altamente eficientes en tareas de clasificación y segmentación en el ámbito de la visión artificial.\n",
    "\n",
    "Inspiradas en el funcionamiento de la corteza visual del cerebro humano, estas redes representan una evolución del perceptrón multicapa. Aunque su uso se popularizó en la década de 1990 con el desarrollo de sistemas de lectura de cheques por parte de AT&T, las CNNs han experimentado una evolución significativa desde entonces.\n",
    "\n",
    "Su arquitectura se compone de capas de convolución, responsables de transformar los datos de entrada, y capas de pooling, encargadas de resumir la información relevante. Posteriormente, se aplican capas densamente conectadas para obtener el resultado final.\n",
    "\n",
    "El auge de las CNNs se vio impulsado por iniciativas como la competencia ILSVRC, que propiciaron avances considerables en este campo. Entre los modelos más destacados se encuentran LeNet-5, AlexNet, VGG, GoogLeNet y ResNet, muchos de los cuales están disponibles como modelos preentrenados para su integración en diversas aplicaciones. Estos modelos, con estructuras de capas más complejas, representan el estado del arte en reconocimiento visual y están al alcance de cualquier investigador interesado en el Deep Learning.\n",
    "\n",
    "Más allá de las arquitecturas conocidas, han surgido modelos más avanzados como DenseNet y EfficientNet, que optimizan el rendimiento y la eficiencia computacional. La transferencia de aprendizaje se ha convertido en una herramienta fundamental, permitiendo adaptar modelos preentrenados a tareas específicas con conjuntos de datos más pequeños, agilizando el entrenamiento y mejorando la generalización.\n",
    "\n",
    "Las CNNs encuentran un amplio uso en tareas de segmentación semántica y detección de objetos, impulsadas por técnicas como U-Net y Mask R-CNN. Adicionalmente, métodos de aprendizaje débilmente supervisado y autoetiquetado están permitiendo entrenar modelos con datos etiquetados de manera menos precisa o incluso sin etiquetar.\n",
    "\n",
    "Para mejorar la interpretabilidad de las CNNs, se han propuesto técnicas de visualización de atención visual, que permiten identificar las partes de una imagen que son más relevantes para la predicción del modelo.\n",
    "\n",
    "Estos avances impulsan el continuo desarrollo de las CNNs, expandiendo su aplicación a diversos campos como el diagnóstico médico, la conducción autónoma y la robótica. La investigación activa en este campo sigue explorando nuevas formas de mejorar la eficiencia, la precisión y la interpretabilidad de las CNNs para abordar desafíos cada vez más complejos en el procesamiento de imágenes y otros tipos de datos.\n",
    "\n",
    "**Autoencoders**\n",
    "\n",
    "Los Autoencoders (AE) son una clase de redes neuronales dentro del ámbito del Deep Learning, caracterizadas por su enfoque en el aprendizaje no supervisado. Aunque se mencionaron por primera vez en la década de 1980, ha sido en los últimos años donde han experimentado un notable interés y desarrollo. La arquitectura de un AE consiste en dos partes principales: el encoder y el decoder. El encoder se encarga de codificar o comprimir los datos de entrada, mientras que el decoder se encarga de regenerar los datos originales en la salida, lo que resulta en una estructura simétrica.\n",
    "\n",
    "Durante el entrenamiento, el AE aprende a reconstruir los datos de entrada en la capa de salida de la red, generalmente implementando restricciones como la reducción de elementos en las capas ocultas del encoder. Esto evita simplemente copiar la entrada en la salida y obliga al modelo a aprender representaciones más significativas de los datos. Entre las aplicaciones principales de los AE se encuentran la reducción de dimensiones y compresión de datos, la búsqueda de imágenes, la detección de anomalías y la eliminación de ruido.\n",
    "\n",
    "Además de los autoencoders estándar, existen varias variaciones que han surgido para abordar diferentes desafíos y aplicaciones específicas, como los Variational Autoencoders (VAE), los Sparse Autoencoders, los Denoising Autoencoders y los Contractive Autoencoders. Estas variaciones amplían el alcance y la versatilidad de los autoencoders en una variedad de contextos de aprendizaje automático, desde la compresión de datos hasta la generación de nuevas muestras y la detección de anomalías en conjuntos de datos complejos.\n",
    "\n",
    "**Redes Recurrentes**\n",
    "\n",
    "Las redes neuronales recurrentes (RNNs) revolucionaron el panorama del machine learning, posicionándose como una herramienta fundamental para procesar y analizar datos secuenciales. A diferencia de las redes neuronales tradicionales con una estructura de capas fija, las RNNs poseen una arquitectura flexible que les permite incorporar información del pasado, presente y futuro, lo que las convirtió en una gran apuesta ante tareas omo el procesamiento del lenguaje natural, el reconocimiento de voz y la predicción de series temporales.\n",
    "\n",
    "Gracias a su capacidad de memoria interna, las RNNs pueden capturar dependencias temporales en los datos secuenciales, una característica crucial para modelar el comportamiento de fenómenos que evolucionan con el tiempo. Esta característica las diferencia de las redes neuronales clásicas, que no tienen en cuenta el contexto temporal de la información.\n",
    "\n",
    "La familia de las RNNs abarca diversas arquitecturas, cada una con sus propias fortalezas y aplicaciones. Entre las más populares encontramos las redes de Elman, las redes de Jordan, las redes Long Short-Term Memory (LSTM) y las redes Gated Recurrent Unit (GRU) que, introducidas en 2015 son una alternativa más ligera y eficiente a las LSTM. \n",
    "\n",
    "El campo de las RNNs ha experimentado un rápido crecimiento en los últimos años, impulsado por avances en investigación y la disponibilidad de conjuntos de datos masivos. Entre las mejoras más notables encontramos las redes neuronales convolucionales recurrentes (CRNNs), las redes neuronales con atención y la integración del aprendizaje por refuerzo. Estas mejoras han ampliado aún más las capacidades de las RNNs, permitiéndolas abordar tareas cada vez más complejas y desafiantes.\n",
    "\n",
    "**Redes Generativas Adversarias**\n",
    "\n",
    "Las Generative Adversarial Networks (GAN) representan una innovadora aplicación del deep learning en la generación de contenido sintético, incluyendo imágenes, videos, música y caras extremadamente realistas. La arquitectura de una GAN consiste en dos componentes principales: un generador y un discriminador. El generador se encarga de crear nuevos datos sintéticos, como imágenes, a partir de un vector aleatorio en el espacio latente. Por otro lado, el discriminador tiene la tarea de distinguir entre datos reales y sintéticos, es decir, determinar si una imagen proviene del conjunto de datos original o si fue creada por el generador.\n",
    "\n",
    "El generador se implementa típicamente utilizando una red neuronal convolucional profunda, con capas especializadas que aprenden a generar características de imágenes en lugar de extraerlas de una imagen de entrada. Algunas de las capas más comunes utilizadas en el modelo del generador son la capa de muestreo (UpSampling2D) que duplica las dimensiones de la entrada, y la capa convolucional de transposición (Conv2DTranspose) que realiza una operación de convolución inversa para generar datos sintéticos.\n",
    "\n",
    "La idea clave detrás de las GAN es el entrenamiento adversarial, donde el generador y el discriminador compiten entre sí en un juego de suma cero. Mientras el generador trata de engañar al discriminador generando datos cada vez más realistas, el discriminador mejora su capacidad para distinguir entre datos reales y sintéticos. Este proceso de competencia continua lleva a la generación de datos sintéticos de alta calidad que son indistinguibles de los datos reales para el discriminador.\n",
    "\n",
    "En los últimos años, las GAN han experimentado avances significativos en términos de nuevas arquitecturas y técnicas de entrenamiento. Por ejemplo, se han desarrollado variantes como las Conditional GAN (cGAN), que permiten controlar las características de los datos generados, y las Progressive GAN (ProgGAN), que generan imágenes de mayor resolución de forma progresiva. Además, se han propuesto técnicas de regularización, como la penalización del gradiente o la normalización espectral, para mejorar la estabilidad y la calidad de las GAN generadas. \n",
    "\n",
    "Las GANs han abierto un abanico de posibilidades en diversos campos como el ámbito de la generación de texto así como aplicaciones en la realidad aumentada donde permiten integrar elementos sintéticos en el mundo real de forma realista, como la creación de avatares virtuales o la superposición de información sobre objetos físicos. Asimismo, de los videojuegos, las GANs se utilizan para desarrollar personajes, escenarios y objetos virtuales de alta calidad para experiencias de juego más inmersivas.\n",
    "\n",
    "\n",
    "**Boltzmann Machine y Restricted Boltzmann Machine**\n",
    "\n",
    "El aprendizaje de la denominada máquina de Boltzmann (BM) se realiza a través de un algoritmo estocástico que proviene de ideas basadas en la mecánica estadística. Este prototipo de red neuronal tiene una característica distintiva y es que el uso de conexiones sinápticas entre las neuronas es simétrico. \n",
    "\n",
    "Las neuronas son de dos tipos: visibles y ocultas. Las neuronas visibles son las que interactúan y proveen una interface entre la red y el ambiente en el que operan, mientras que las neuronas actúan libremente sin interacciones con el entorno. Esta máquina dispone de dos modos de operación. El primero es la condición de anclaje donde las neuronas están fijas por los estímulos específicos que impone el ambiente. El otro modo es la condición de libertad, donde tanto las neuronas ocultas como las visibles actúan libremente sin condiciones impuestas por el medio ambiente. Las maquinas restringidas de Boltzmann (RBM) solamente toman en cuenta aquellos modelos en los que no existen conexiones del tipo visible-visible y oculta-oculta. Estas redes también asumen que los datos de entrenamiento son independientes y están idénticamente distribuidos.\n",
    "\n",
    "Una forma de estimar los parámetros de un modelo estocástico es calculando la máxima verosimilitud. Para ello, se hace uso de los Markov Random Fiels (MRF), ya que al encontrar los parámetros que maximizan los datos de entrenamiento bajo una distribución MRF, equivale a encontrar los parámetros $\\theta$ que maximizan la verosimilitud de los datos de entrenamiento, Fischer e Igel (2012). Maximizar dicha verosimilitud es el objetivo que persigue el algoritmo de entrenamiento de una RBM. A pesar de utilizar la distribución MRF, computacionalmente hablando se llega a ecuaciones inviables de implementar. Para evitar el problema anterior, las esperanzas que se obtienen de MRF pueden ser aproximadas por muestras extraídas de distribuciones basadas en las técnicas de Markov Chain Monte Carlo Techniques (MCMC). Las técnicas de MCMC utilizan un algoritmo denominado muestreo de Gibbs con el que obtenemos una secuencia de observaciones o muestras que se aproximan a partir de una distribución de verosimilitud de múltiples variables aleatorias. La idea básica del muestreo de Gibss es actualizar cada variable posteriormente en base a su distribución condicional dado el estado de las otras variables.\n",
    "\n",
    "**Deep Belief Network**\n",
    "\n",
    "Una red Deep Belief Network tal como demostró Hinton se puede considerar como un “apilamiento de redes restringidas de Boltzmann”. Tiene una estructura jerárquica que, como es sabido, es una de las características del deep learning. Como en el anterior modelo, esta red también es un modelo en grafo estocástico, que aprende a extraer una representación jerárquica profunda de los datos de entrenamiento. Cada capa de la RBM extrae un nivel de abstracción de características de los datos de entrenamiento, cada vez más significativo; pero para ello, la capa siguiente necesita la información de la capa anterior lo que implica el uso de las variables latentes. \n",
    "\n",
    "Estos modelos caracterizan la distribución conjunta $h_k$ entre el vector de observaciones *x* y las capas ocultas, donde $x=h_0$, es una distribución condicional para las unidades visibles limitadas sobre las unidades ocultas que pertenecen a la RBM en el nivel *k*, y es la distribución conjunta oculta visible en la red RBM del nivel superior o de salida. \n",
    "\n",
    "El entrenamiento de esta red puede ser híbrido, empezando por un entrenamiento no supervisado para después aplicar un entrenamiento supervisado para un mejor y más óptimo ajuste, aunque pueden aplicarse diferentes tipos de entrenamiento, Bengio et al. (2007) y Salakhutdinov (2014) Para realizar un entrenamiento no supervisado se aplica a las redes de creencia profunda con Redes restringidas de Boltzmann el método de bloque constructor que fue presentado por Hinton (2006) y por Bengio (2007)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da222ded-d7cf-44df-8e67-ecc8fb529857",
   "metadata": {},
   "source": [
    "### Software\n",
    "\n",
    "Como se verá en los siguientes epígrafes, la opción preferida para este módulo de Deep Learning es el software llamado Keras que está programado en Python. En términos de eficiencia y de aprendizaje Keras presenta unas ventajas importantes que se especifican más adelante.\n",
    "\n",
    "Aunque nuestra preferencia a nivel formativo es el **uso de Keras y Tensorflow**, a continuación serán descritos los principales softwares con los que poder realizar implementaciones de arquitecturas de aprendizaje profundo: *TensorFlow*, *Keras*, *Pytorch*, *MXNET*, *Caffe* y *JAX*. \n",
    "\n",
    "Por su parte, también presentaremos **Colaboratory Environment (Colab)**, una herramienta de Google que dispone en la web y que no requiere ninguna instalación en nuestros ordenadores. Esta propuesta de Google resulta muy interesante dado que no requiere coste alguno, se puede ejecutar desde cualquier lugar aumentando nuestros recursos a la hora de trabajar con Deep Learning y admitiendo a su vez la implementación tanto de código Python como de R.\n",
    "\n",
    "**TensorFlow**\n",
    "\n",
    "TensorFlow es una biblioteca de código abierto para el cálculo numérico desarrollada por Google. Es una de las herramientas de Deep Learning más populares y ampliamente utilizadas, conocida por su flexibilidad, escalabilidad y comunidad activa. TensorFlow ofrece una amplia gama de funciones para construir, entrenar y desplegar modelos de Deep Learning, incluyendo:\n",
    "\n",
    "- Soporte para una variedad de arquitecturas de redes neuronales: permite construir una amplia gama de arquitecturas de redes neuronales, desde redes convolucionales y recurrentes hasta modelos de atención y redes generativas adversarias (GANs)\n",
    "- Escalabilidad a grandes conjuntos de datos: está diseñado para manejar grandes conjuntos de datos y puede distribuirse en múltiples GPUs o TPU para acelerar el entrenamiento de modelos\n",
    "- Amplia gama de herramientas de visualización y depuración: proporciona una variedad de herramientas para visualizar y depurar modelos de Deep Learning, lo que facilita la identificación y resolución de problemas\n",
    "- Gran comunidad y recursos: cuenta con una gran y activa comunidad de desarrolladores y usuarios que proporcionan soporte y comparten recursos\n",
    "\n",
    "**Pytorch**\n",
    "\n",
    "PyTorch es una biblioteca de código abierto para el aprendizaje automático desarrollada por Facebook. Es conocida por su sintaxis intuitiva y facilidad de uso, lo que la convierte en una opción popular para investigadores y desarrolladores principiantes. PyTorch ofrece características similares a TensorFlow, incluyendo:\n",
    "\n",
    "- Soporte para una variedad de arquitecturas de redes neuronales: permite construir una amplia gama de arquitecturas de redes neuronales, desde redes convolucionales y recurrentes hasta modelos de atención y GANs\n",
    "- Ejecución dinámica de gráficos: utiliza un motor de ejecución de gráficos dinámico, lo que permite modificar los modelos durante el entrenamiento, lo que facilita la experimentación y el ajuste fino\n",
    "- Amplia gama de bibliotecas y herramientas de terceros: se beneficia de un ecosistema rico de bibliotecas y herramientas de terceros que amplían sus capacidades\n",
    "- Facilidad de uso: tiene una sintaxis similar a Python, lo que la hace fácil de aprender y usar para desarrolladores con experiencia en Python\n",
    "\n",
    "**Keras**\n",
    "\n",
    "Keras es una biblioteca de código abierto para el aprendizaje automático de alto nivel que se ejecuta sobre TensorFlow o PyTorch. Es conocida por su simplicidad y facilidad de uso, lo que la convierte en una opción popular para principiantes y para desarrollar prototipos de modelos rápidamente. Keras ofrece una interfaz de alto nivel que abstrae las complejidades de las bibliotecas subyacentes, como TensorFlow o PyTorch, lo que permite a los usuarios centrarse en la construcción y el entrenamiento de modelos sin necesidad de profundizar en los detalles de implementación. Entre las principales características de Keras destaca:\n",
    "\n",
    "- Simplicidad: tiene una sintaxis intuitiva y fácil de aprender, lo que la hace ideal para principiantes y para desarrollar prototipos de modelos rápidamente\n",
    "- Facilidad de uso: ofrece una API de alto nivel que abstrae las complejidades de las bibliotecas subyacentes, como TensorFlow o PyTorch, lo que permite a los usuarios centrarse en la construcción y el entrenamiento de modelos sin necesidad de profundizar en los detalles de implementación\n",
    "- Flexibilidad: permite construir una amplia gama de modelos de Deep Learning, desde redes neuronales convolucionales y recurrentes hasta modelos de atención y redes generativas adversarias (GANs)\n",
    "- Modularidad: al ser una biblioteca modular que permite a los usuarios combinar diferentes componentes para construir sus modelos personalizados\n",
    "- Soporte para múltiples plataformas: se puede utilizar en una variedad de plataformas, incluyendo Windows, macOS y Linux.\n",
    "\n",
    "\n",
    "**JAX**\n",
    "\n",
    "JAX, desarrollada por Google Research, se posiciona como una biblioteca de Python para el aprendizaje automático y el cálculo numérico, diseñada para ofrecer un rendimiento y una flexibilidad excepcionales, especialmente en el entrenamiento de modelos de deep learning en aceleradores como GPUs y TPUs.\n",
    "\n",
    "Su enfoque se basa en la composición de funciones puras y transformaciones automáticas de gradiente, lo que la convierte en una herramienta ideal para implementar algoritmos de aprendizaje automático diferenciables y de alto rendimiento. Entre sus características destacadas encontramos:\n",
    "\n",
    "- Autodiferenciación: calcula automáticamente gradientes (autodiferenciación), simplificando el desarrollo de modelos de deep learning\n",
    "- Composición eficiente de transformaciones: combina operaciones elementales en funciones compuestas para un procesamiento eficiente\n",
    "- Integración con frameworks: se integra con frameworks de deep learning como TensorFlow y PyTorch, aprovechando las ventajas de cada uno\n",
    "- Paralelización y distribución: permite ejecutar operaciones en paralelo y de manera distribuida, ideal para grandes conjuntos de datos\n",
    "- Altas prestaciones para el entrenamiento de modelos: sobresale por su capacidad de computación de alto rendimiento, haciéndola ideal para entrenar modelos de deep learning complejos de manera eficiente. Así, se ha convertido en una opción atractiva para aquellos que manejan grandes conjuntos de datos y buscan optimizar el tiempo de entrenamiento\n",
    "- Flexibilidad para la investigación y experimentación: facilita la implementación de nuevas arquitecturas y algoritmos, permitiendo explorar diferentes enfoques y optimizar el rendimiento de los modelos\n",
    "- Personalización de flujos de trabajo: permite definir funciones y transformaciones personalizadas, proporcionando un control preciso sobre el pipeline de trabajo. Esto resulta útil para adaptar el proceso de entrenamiento a necesidades específicas y optimizar el rendimiento para tareas concretas\n",
    "\n",
    "**Mxnet**\n",
    "\n",
    "MXNet es una biblioteca de código abierto para el aprendizaje automático desarrollada por Apache Software Foundation. Es conocida por su escalabilidad, flexibilidad y soporte para múltiples lenguajes de programación, incluyendo Python, R y C++. MXNet ofrece características similares a TensorFlow y PyTorch, incluyendo:\n",
    "\n",
    "- Soporte para una variedad de arquitecturas de redes neuronales: permite construir una amplia gama de arquitecturas de redes neuronales, desde redes convolucionales y recurrentes hasta modelos de atención y GANs\n",
    "- Escalabilidad a grandes conjuntos de datos: está diseñado para manejar grandes conjuntos de datos y puede distribuirse en múltiples GPUs o TPU para acelerar el entrenamiento de modelos\n",
    "- Soporte para múltiples lenguajes de programación: se puede utilizar con Python, R y C++, lo que lo hace accesible a una amplia gama de desarrolladores\n",
    "- Flexibilidad: permite a los usuarios personalizar y extender la biblioteca para satisfacer sus necesidades específicas\n",
    "\n",
    "**Caffe**\n",
    "\n",
    "Caffe es un marco de código abierto para el aprendizaje profundo desarrollado por la Universidad de California, Berkeley. Es conocido por su simplicidad, velocidad y eficiencia, lo que lo convierte en una opción popular para aplicaciones de Deep Learning en tiempo real. Caffe ofrece características similares a TensorFlow y PyTorch, incluyendo:\n",
    "\n",
    "- Soporte para una variedad de arquitecturas de redes neuronales: permite construir una amplia gama de arquitecturas de redes neuronales, desde redes convolucionales y recurrentes hasta modelos de atención y GANs\n",
    "- Entrenamiento rápido y eficiente: está optimizado para el rendimiento y la eficiencia, lo que lo hace ideal para aplicaciones de aprendizaje profundo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c33d38-1624-4102-b20c-e9caac764a6e",
   "metadata": {},
   "source": [
    "#### Google Colab\n",
    "\n",
    "El entorno Colab (Google Colaboratory) es una potente herramienta de google para ejecutar código incluido el deep Dearning y que está disponible en la web (https://colab.research.google.com/). Se ha desarrollado para Python, pero actualmente también se puede ejecutar código de R. Esta funcionalidad puede importar un conjunto de datos de imágenes, entrenar un clasificador con este conjunto de datos y evaluar el modelo con tan solo usar unas pocas líneas de código. Los cuadernos de Colab ejecutan código en los servidores en la nube de Google, lo que nos permite aprovechar la potencia del hardware de Google, incluidas las GPU y TPU, independientemente de la potencia de tu equipo. Lo único que se necesita es un navegador.\n",
    "\n",
    "Con Colab se puede aprovechar toda la potencia de las bibliotecas más populares de Python para analizar y visualizar datos. La celda de código de abajo utiliza NumPy para generar datos aleatorios y Matplotlib para visualizarlos. Para editar el código, solo se tiene que hacer clic en la celda.\n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_1.png\" width=\"720\" height=\"500\">\n",
    "\n",
    "Este es el menú principal de colab desde donde podemos gestionar nuestros proyectos:\n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_nuevo_fichero.png\" width=\"720\" height=\"500\">\n",
    "\n",
    "Desde el `menú Archivo`, como en la mayor parte de los programas, podemos llevar a cabo las operaciones habituales de abrir y guardar los ficheros en diferentes formatos. En este caso se pueden abrir ficheros de Jupyter/Python desde cualquier dispositivo externo, desde el repositorio Drive o de Github: \n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_importa.png\" width=\"720\" height=\"500\">\n",
    "\n",
    "Si queremos subir un fichero que tenemos en nuestro ordenador vamos a `Archivo/Subir` cuaderno y podemos elegir nuestro archivo cuando se despliegue la siguiente pantalla:\n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_importa_archivo.png\" width=\"720\" height=\"500\">\n",
    "\n",
    "Como se ha comentado también se pueden importar archivos desde GitHub introduciendo la url de GitHub: \n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_importa_github.png\" width=\"720\" height=\"500\">\n",
    "\n",
    "Por último, *colab* nos permite tener acceso tanto a GPUs de forma como a  CPUs más potentes que nuestro ordenador de escritorio de forma gratuita.\n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_entorno_ejecucion_inicio.png\" width=\"720\" height=\"500\">\n",
    "<img src=\"../apuntes/soporte_imagenes/colab_entorno_ejecucion.png\" width=\"720\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8bfdb9-0ff0-477f-9d0f-eb5692fc9b0c",
   "metadata": {},
   "source": [
    "## Conceptos básicos\n",
    "\n",
    "**ESTO VA DESDE Arquitectura de red hasta apartado 7.3 del documento del año pasado**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1eb4f-a438-4036-b518-1f29bc615acb",
   "metadata": {},
   "source": [
    "## Redes Convolucionales\n",
    "\n",
    "### Clasificación y segmentación de imágenes\n",
    "\n",
    "### Clasificación de textos\n",
    "\n",
    "Las redes convolucionales son actualmente utilizadas para diferentes propósitos: tratamiento de\n",
    "imágenes (visión por computador, extracción de características, segmentación, etc.), generación\n",
    "y clasificación de texto (o audio), predicción de series temporales, etc. En este caso, veremos en\n",
    "detalle un ejemplo de clasificación de texto.\n",
    "\n",
    "Se presenta a continuación una aplicación práctica de clasificación de texto multiclase a partir de\n",
    "redes Convolucionales de una dimensión. Para ello, se utiliza una bbdd referida a las\n",
    "reclamaciones de los usuarios ante una entidad bancaria en función del tipo de producto.\n",
    "\n",
    "En primer lugar, se importan las librerías a utililizar y se le el fichero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b69b088a-814b-4814-ab32-49ca7e12842e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p_san\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cccc7c-6888-457d-b883-17ee036c36cc",
   "metadata": {},
   "source": [
    "El fichero de trabajo contiene una serie de reclamaciones que no vienen acompañadas con su texto asociado. \n",
    "Se considera que lo más adecuado es excluir tales instancias del dataset de partida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce4f213-101e-4882-8041-3e8f3eeeb911",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('C:/DEEP LEARNING/consumer_complaints.csv')\n",
    "datos = datos[['product', 'consumer_complaint_narrative']] # variables de\n",
    "interés\n",
    "datos =\n",
    "datos.dropna(subset=['product','consumer_complaint_narrative']).reset_index\n",
    "(drop=True) # registros con texto no informado son eliminados de la muestra\n",
    "print('Tamaño de los datos:', datos.shape)\n",
    "Tamaño de los datos: (66806, 2)\n",
    "sns.countplot(y='product', data=datos, order =\n",
    "datos['product'].value_counts().index)\n",
    "plt.xlabel('Reclamaciones'), plt.ylabel('Producto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9cc6f1-6d14-4d3b-b6c4-d34b64182ba1",
   "metadata": {},
   "source": [
    "Como puede verse, se parte de once tipos de productos diferentes; si bien, para varios de ellos el\n",
    "número de reclamaciones no es considerado significativo por el área legal de la entidad. Por ello, y en base a la similitud de los productos, se agrupan las cuatro categorías con un menor número\n",
    "reclamaciones en\n",
    "- Prepaid card: se incluye en la categoría de \"Credit card\"\n",
    "- Payday loan: se incluye en la categoría \"Bank account or service\"\n",
    "- Money transfers y Other financial service: forman un grupo conjunto denominado \"Money transfers and Other financial service\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e22d5-9b65-46e8-b579-ff079ffe3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupaciones\n",
    "datos['product'] = np.where(datos['product']=='Payday loan', 'Bank account\n",
    "or service', datos['product']) # préstamos\n",
    "datos['product'] = np.where(datos['product']=='Prepaid card', 'Credit\n",
    "card', datos['product']) # créditos\n",
    "tipo_producto = ['Money transfers','Other financial service'] # otros\n",
    "servicios financieros\n",
    "datos['product'] = np.where(datos['product'].isin(tipo_producto), 'Money\n",
    "transfers and Other', datos['product'])\n",
    "sns.countplot(y='product', data=datos, order =\n",
    "datos['product'].value_counts().index)\n",
    "plt.xlabel('Reclamaciones'), plt.ylabel('Producto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e61bb7a-0c16-4440-87a2-45c55c39517d",
   "metadata": {},
   "source": [
    "De esta forma, el número de grupos ha sido distribuido de una forma más equitativa. A modo de\n",
    "ejemplo, se muestra una de las reclamaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6516c-5da3-466e-ac63-d2c38b9baf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reclamaciones(df, elemento):\n",
    "    df = df.loc[elemento].to_list()\n",
    "    return df\n",
    "print('Producto:', plot_reclamaciones(datos, 100)[0])\n",
    "print('Reclamacion:', plot_reclamaciones(datos, 100)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03910561-c880-45e5-ac46-9cdc8db488fc",
   "metadata": {},
   "source": [
    "Como puede verse, la reclamación 101 del dataset está asociada a un préstamo al consumo. Sin\n",
    "embargo, lo verdaderamente interesante del texto de ejemplo es la necesidad de realizar un\n",
    "preprocesado a los textos puesto que algunos símbolos, caracteres o, incluso palabras, no son\n",
    "relevantes para que la red sea capaz de interpretar el contenido del mismo. Por tanto, se lleva a\n",
    "cabo lo siguiente:\n",
    "- Conversión del texto a minúsculas\n",
    "- Exclusión del texto el contenido cifrado (XXXX)\n",
    "- Eliminación de caracteres extraños\n",
    "- Para poder hacer este preprocesado de textos se hace uso del paquete re de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12d285-6b42-4b15-9302-0e2b325ec972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesado(reclamacion):\n",
    "    reclamacion = reclamacion.lower() # texto en minúsculas\n",
    "    reclamacion = reclamacion.replace('x','') # cambio X por espacio\n",
    "    reclamacion = re.compile('[/(){}\\[\\]\\|@,;]').sub('', reclamacion) # símbolos extraños (1)\n",
    "    reclamacion = re.compile('[^0-9a-z #+_]').sub('', reclamacion) # símbolos extraños (2)\n",
    "    return reclamacion\n",
    "datos['consumer_complaint_narrative'] = datos['consumer_complaint_narrative'].apply(preprocesado) # aplicación de la función"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad826aa-3c71-4789-b904-dd633e05c9da",
   "metadata": {},
   "source": [
    "Se presenta de nuevo el ejemplo anterior para ver el resultado del procesamiento de textos\n",
    "realizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff3c46b-a79f-40f3-a3c7-13166780327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Producto:', plot_reclamaciones(datos, 100)[0])\n",
    "print('Reclamacion:', plot_reclamaciones(datos, 100)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e41ee4-e4d2-41fc-93d8-e923b762b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "X_texto = datos['consumer_complaint_narrative']\n",
    "Y_label = pd.get_dummies(datos['product']).values # las categorías son\n",
    "convertidas a variable dummy\n",
    "X_train_text, X_test_text, Y_train, Y_test =\n",
    "train_test_split(X_texto,Y_label, test_size = 0.2, random_state = seed)\n",
    "print('Entrenamiento:', X_train_text.shape)\n",
    "print('Test:', X_train_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0c422-14ad-45fe-81bb-3a52ce8e4f11",
   "metadata": {},
   "source": [
    "Antes de definir la arquitectura de la red, se lleva a cabo la conversión del texto a variables\n",
    "numéricas que es el input que puede leer la red. Para ello, se realiza:\n",
    "- La vectorización del texto asociado a las reclamaciones.\n",
    "- El truncamiento y rellenado de las secuencias de entrada para igualar la longitud en la\n",
    "modelización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797f5e8-c8a5-4131-8d07-36d112751ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 25000 # frecuencia de palabras\n",
    "MAX_SEQUENCE_LENGTH = 200 # número de palabras en cada reclamacion\n",
    "EMBEDDING_DIM = 150 # dimensión del embedding\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS,\n",
    "filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(X_train_text.values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Tokens:', len(word_index))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train_text.values)\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Datos de entrada:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76028196-da73-4a54-8f55-49021dc80ae1",
   "metadata": {},
   "source": [
    "Por último, se crea la red neuronal siguiendo el método funcional. La red tiene las siguientes capas:\n",
    "- Entrada: de 200 neuronas pues corresponde con la longitud de las secuencias\n",
    "- Embedding: de dimensión 200 y toma como input el número máximo de palabras (25.000)\n",
    "- Convolucional: de 64 neuronas\n",
    "- MaxPooling:\n",
    "- Densa: de 32 neuronas y con función de activación \"relu\"\n",
    "- Salida: capa densa con 8 neuronas (número de categorías del target) y función de activación \"softmax\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44a917-af0e-4c26-819d-f69defd1b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capa de entrada\n",
    "inputs = tf.keras.Input(shape=(X_train.shape[1],))\n",
    "embedding = tf.keras.layers.Embedding(input_dim=MAX_NB_WORDS,\n",
    "output_dim=EMBEDDING_DIM)(inputs)\n",
    "capa_conv = tf.keras.layers.Conv1D(filters=64,\n",
    "kernel_size=3,\n",
    "padding='valid',\n",
    "activation='relu')(embedding)\n",
    "max_pooling = tf.keras.layers.GlobalMaxPooling1D()(capa_conv)\n",
    "capa_densa = tf.keras.layers.Dense(units=32,\n",
    "activation='relu',\n",
    "kernel_regularizer=tf.keras.regularizers.l2(0.01))(max_pooling)\n",
    "out = tf.keras.layers.Dense(units=Y_train.shape[1],\n",
    "activation='softmax')(capa_densa)\n",
    "modelo = tf.keras.Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb94be-5fc4-43ce-b8a5-ab73d2971083",
   "metadata": {},
   "source": [
    "El summary nos muestra el número de parámetros por capa y el número de parámetros total.\n",
    "Puede verse que el alto número de parámetros viene, principalmente, por la capa de Embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79ca56-7df1-4164-8304-ee0c82b8b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e3ef05-c53a-4f34-be43-2827e40dc74c",
   "metadata": {},
   "source": [
    "La métrica utilizada para evaluar el desempeño es el accuracy y, como es un problema de\n",
    "clasificación multiclase, como función de pérdida categorical_crossentropy. Por su parte, se\n",
    "emplea Adam para la utilización del algoritmo de propagación del error hacia atrás (parámetros\n",
    "por defecto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56005e4b-c512-4671-a2f5-6cf308069ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f79fb06-a126-4c77-80d9-c39de2adbab2",
   "metadata": {},
   "source": [
    "Para el proceso de entrenamiento de la red destacar:\n",
    "- Un máximo de 10 épocas y actualización de los pesos cada 128 muestras\n",
    "- Reserva del 20% del dataset para ser usado como validación\n",
    "- Uso de parada temprana para recoger el mejor modelo posible en el proceso iterativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb696d9-3855-4c5b-bdcb-f72ed79cdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "history = modelo.fit(X_train, Y_train,\n",
    "epochs=epochs,\n",
    "batch_size=batch_size,\n",
    "validation_split=0.2,\n",
    "\n",
    "callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0d9865-43a9-4b0f-994b-1fd98181b12f",
   "metadata": {},
   "source": [
    "Una vez realizado el entrenamiento, se visualiza el proceso para conocer su convergencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af7a0c-5a92-4021-b487-d9eb5dba590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construcción de un data.frame\n",
    "df_train=pd.DataFrame(history.history)\n",
    "df_train['epochs']=history.epoch\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.plot(df_train['epochs'], df_train['loss'], label='train_loss')\n",
    "ax1.plot(df_train['epochs'], df_train['val_loss'], label='val_loss')\n",
    "ax2.plot(df_train['epochs'], df_train['accuracy'], label='train_acc')\n",
    "ax2.plot(df_train['epochs'], df_train['val_accuracy'], label='val_acc')\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d105f-f474-4c46-a9d7-ba9186e97654",
   "metadata": {},
   "source": [
    "Finalmente, se estima la bondad de ajuste con la muestra de test. Para ello, como esta muestra\n",
    "hace referencia a la puesta en producción del modelo, es necesario crear las secuencias de este\n",
    "nuevo dataset en función de la tokenización del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f30645-09db-4ef9-8620-0fc117915028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tokenizer.texts_to_sequences(X_test_text)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a336c-5643-4f90-b2c0-e6e808fcaf85",
   "metadata": {},
   "source": [
    "Y ahora ya sí, se realizan las predicciones y se evaluar el performance del modelo creado en la\n",
    "muestra de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed370694-cf6a-4a7a-b6ca-922ad3292e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uso de argmax para pasar de probabilidad a estimación final\n",
    "Y_test_pred = np.argmax(modelo.predict(X_test), axis=1) # predicción de la\n",
    "etiqueta\n",
    "Y_test_label = np.argmax(Y_test, axis=1) # obtención de las etiquetas sin\n",
    "dummy\n",
    "print('accuracy - test:', np.round(accuracy_score(Y_test_label,\n",
    "Y_test_pred),5))\n",
    "sns.heatmap(confusion_matrix(Y_test_pred, Y_test_label), annot = True,\n",
    "fmt='.0f') # matriz de confusión\n",
    "plt.title('Matriz de confusión - test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe40eb-8918-49c9-82c5-574c4cb57462",
   "metadata": {},
   "source": [
    "## Redes recurrentes: Elman, Jordan, LSTM y GRU\n",
    "\n",
    "### Forecasting en series de tiempo\n",
    "\n",
    "### Clasificación y generación de textos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ddb479-9a5b-4d2e-9447-d175db12ef36",
   "metadata": {},
   "source": [
    "## AutoEncoders\n",
    "\n",
    "### Detección de anomalías"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee2be0f-e8c7-4473-9205-3956236b288d",
   "metadata": {},
   "source": [
    "## Arquitecturas preentrenadas\n",
    "\n",
    "Las **arquitecturas pre-entrenadas** en Deep Learning son modelos de redes neuronales que han sido previamente entrenados en grandes conjuntos de datos para realizar tareas específicas como clasificación de imágenes, generación de texto o reconocimiento de voz. Durante el entrenamiento, estos modelos aprenden patrones complejos de los datos, lo que les permite realizar tareas relacionadas con alta precisión y generalización. \n",
    "\n",
    "El funcionamiento de las arquitecturas pre-entrenadas se basa en el concepto de **transferencia de aprendizaje**. La transferencia de aprendizaje consiste en aprovechar el conocimiento aprendido en una tarea para aplicarlo a otra tarea diferente; es decir, se utiliza como base para realizar tareas específicas con mayor facilidad.\n",
    "\n",
    "Las arquitecturas pre-entrenadas suelen ser diseñadas por investigadores y equipos de desarrollo en instituciones académicas, laboratorios de investigación y empresas de tecnología. Estos expertos desarrollan las arquitecturas, definen el proceso de entrenamiento y seleccionan los conjuntos de datos adecuados para cada tarea. Algunas de las organizaciones e instituciones que lideran el diseño de arquitecturas pre-entrenadas son:\n",
    "\n",
    "- *Google AI*: ha desarrollado arquitecturas pre-entrenadas como BERT y Vision Transformers, las cuales han tenido un gran impacto en el procesamiento del lenguaje natural y la visión artificial, respectivamente. Además, en los últimos años, han publicado Gema y Gemini, que permiten el aprendizaje automático en general, ofreciendo flexibilidad, escalabilidad y alto rendimiento en diversas tareas\n",
    "- *Facebook AI Research*: ha contribuido con arquitecturas pre-entrenadas como FAIRSEQ y Detectron2, que han impulsado el rendimiento en tareas de procesamiento del lenguaje natural y detección de objetos, respectivamente. Además, también ha desarrollado Llama, Llama2 y Llama3, modelos que han destacado por su versatilidad y precisión en aplicaciones de reconocimiento de voz y procesamiento de texto.\n",
    "- *OpenAI*: conocido por sus arquitecturas pre-entrenadas líderes como GPT-3 y Whisper, ha lanzado recientemente GPT-4. Este modelo promete mejorar la comprensión contextual y la generación de texto, lo que podría tener un gran impacto en aplicaciones de procesamiento del lenguaje natural. GPT-4 representa un avance significativo en la investigación de inteligencia artificial y abre nuevas posibilidades para sistemas más avanzados.\n",
    "\n",
    "Estos modelos son entrenados en grandes clústeres de servidores con hardware especializado, como GPUs y TPUs, utilizando conjuntos de datos masivos y técnicas de optimización avanzadas. A día de hoy se han convertido en un elemento capital para los desarrolladores de aprendizaje automático puesto que nos permite aprovechar modelos entrenados previamente que, en condiciones normales, sería casi imposible realizar por centros no especializados. Así, podríamos destacar las siguientes ventajas:\n",
    "- Ahorro de tiempo y recursos: al aprovechar el conocimiento pre-entrenado, nos permiten a los desarrolladores ahorrar tiempo y recursos computacionales en comparación con entrenar un modelo desde cero\n",
    "- Mayor rendimiento: suelen ofrecer un rendimiento superior a los modelos entrenados desde cero, especialmente para tareas complejas\n",
    "- Facilidad de uso: las librerías y entornos  facilitan el acceso y la utilización de arquitecturas pre-entrenadas, incluso para usuarios con poca experiencia en Deep Learning\n",
    "\n",
    "Como se ha dicho, cada vez más se emplean este tipo de arquitecturas para realizar tareas que, con otro tipo de diseños de aprendizaje automático serían más complejas y costosas de abordar. En este aspecto, destacar que a la hora de elegir qué tipo de arquitectura pre-entrenada es adecuada para un caso de uso es necesario tener en cuenta la tarea específica a abordar, el conjunto de datos con los que ha sido entrenada y la similaridad con los nuestros propios así como si disponemos de ciertas limitaciones en cuanto a recursos computacionales.\n",
    "\n",
    "Por último, destacar que existen diversas librerías y entornos que facilitan el trabajo con arquitecturas pre-entrenadas. Algunas de las opciones más interesantes son:\n",
    "- TensorFlow Hub: es un repositorio de módulos pre-entrenados para TensorFlow, que incluye una amplia gama de arquitecturas pre-entrenadas para diversas tareas.\n",
    "- Hugging Face Hub: es una plataforma similar a TensorFlow Hub, pero que ofrece soporte para múltiples frameworks de Deep Learning, incluyendo TensorFlow, PyTorch y JAX.\n",
    "\n",
    "### Paquetes específicos en Python\n",
    "\n",
    "#### Transformers\n",
    "\n",
    "Transformers es una biblioteca de código abierto en Python desarrollada por Hugging Face que proporciona un conjunto de herramientas para trabajar con modelos de lenguaje basados en redes neuronales transformadoras.\n",
    "\n",
    "Esta librería se caracteriza por su gran variedad de modelos pre-entrenados y capacidad de hacer fine-tuning de modelos. Así, entre sus principales ventajas podemos citar:\n",
    "- La facilidad de uso\n",
    "- La flexibilidad y la escalabilidad\n",
    "- La comunidad activa de desarrolladores\n",
    "\n",
    "Finalmente, indicamos proporcionamos una serie de recursos adicionales:\n",
    "\n",
    "- Sitio web de Transformers: https://huggingface.co/docs/transformers/en/index\n",
    "- Documentación de Transformers: https://huggingface.co/docs\n",
    "- Tutoriales de Transformers: https://www.youtube.com/watch?v=QEaBAZQCtwE\n",
    "\n",
    "\n",
    "### Tensorflow-Hub\n",
    "\n",
    "Tensorflow-Hub alberga una gran colección de módulos de aprendizaje automático pre-entrenados y reutilizables, creados por Google y la comunidad de TensorFlow.\n",
    "\n",
    "Esta librería se caracteriza por disponer de una gran cantidad de modelos pre-entrenados para diferentes tareas relacionadas con el aprendizaje profundo. Así, entre sus principales ventajas podemos citar:\n",
    "- El acceso a modelos pre-entrenados de última generación\n",
    "- La flexibilidad y personalización\n",
    "- La facilidad de\n",
    "\n",
    "Finalmente, indicamos proporcionamos una serie de recursos adicionales:\n",
    "\n",
    "- Sitio web de TensorFlow Hub: https://www.tensorflow.org/hub\n",
    "- Documentación de TensorFlow Hub: https://www.tensorflow.org/hub\n",
    "- Tutoriales de TensorFlow Hub: https://www.tensorflow.org/hub/tutorials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec8ec7-057b-43e4-8601-dc0286826190",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Arquitecturas Zero-shot\n",
    "\n",
    "Las **arquitecturas Zero-Shot**, también conocidas como *modelos de Aprendizaje por Analogía* son capaces de realizar tareas de clasificación sin necesidad de entrenamiento específico para cada categoría. En su lugar, estas arquitecturas aprenden representaciones vectoriales de conceptos a partir de datos no etiquetados, lo que les permite generalizar a nuevas categorías sin haberlas visto nunca antes.\n",
    "\n",
    "<img src=\"../apuntes/soporte_imagenes/zero-shot.png\" width=\"720\" height=\"720\">\n",
    "\n",
    "#### Uso en imágenes\n",
    "\n",
    "En el ámbito de la visión artificial, las arquitecturas Zero-Shot para imágenes han demostrado ser particularmente útiles para tareas como la clasificación de imágenes de escenas naturales, la identificación de animales y la detección de objetos. Entre los modelos más destacados en esta área se encuentran:\n",
    "- *ImageNet-pretrained CLIP*: basado en la arquitectura CLIP (Contrastive Language-Image Pre-training), este modelo utiliza representaciones de imágenes y texto para realizar clasificación Zero-Shot de imágenes con gran precisión\n",
    "- *ResNet-pretrained ZSL*: Este modelo combina la arquitectura ResNet, conocida por su rendimiento en tareas de clasificación de imágenes, con un enfoque Zero-Shot basado en la distancia entre representaciones\n",
    "\n",
    "`MATERIAL COMPLEMENTARIO - NOTEBOOK`: ejemplo en `Zero-shot: clasificación animales`\n",
    "\n",
    "#### Uso en texto\n",
    "\n",
    "En el procesamiento del lenguaje natural, las arquitecturas Zero-Shot para texto han ganado popularidad para tareas como la clasificación de documentos, la extracción de información y la categorización de textos. Algunos modelos representativos en este campo son:\n",
    "\n",
    "- *BERT-pretrained ZSL*: basado en la arquitectura BERT (Bidirectional Encoder Representations from Transformers), este modelo utiliza representaciones contextuales de palabras para realizar clasificación Zero-Shot de texto con gran precisión\n",
    "- *Siamese Networks with Word Embeddings*: este enfoque utiliza redes siamesas, un tipo de red neuronal que aprende a comparar pares de entradas, para clasificar texto Zero-Shot utilizando representaciones de palabras pre-entrenadas.\n",
    "\n",
    "### Detección de objetos\n",
    "\n",
    "La **detección de objetos** es una tarea fundamental en el ámbito de la visión artificial, que consiste en identificar y localizar objetos dentro de una imagen o video. Las arquitecturas pre-entrenadas para la detección de objetos han revolucionado este campo, ofreciendo modelos de alta precisión y eficiencia. Entre los modelos más utilizados se encuentran:\n",
    "\n",
    "- *Faster R-CNN*: Este modelo combina la arquitectura de redes convolucionales profundas (CNN) con una región de propuesta de regiones (RPN) para detectar y localizar objetos con gran precisión\n",
    "- *YOLOv5*: Este modelo destaca por su velocidad y eficiencia, utilizando una arquitectura basada en convoluciones y bloques de atención para detectar objetos en tiempo real\n",
    "\n",
    "`MATERIAL COMPLEMENTARIO - VIDEOTUTORIAL`: ejemplo en `Arquitecturas Tensorflow-Hub`\n",
    "\n",
    "### Conversión de voz a texto\n",
    "\n",
    "La *conversión de voz a texto*, también llamado como **Speech-to-Text** es una tarea crucial para la interacción hombre-máquina. Las arquitecturas pre-entrenadas para este tipo de casos han impulsado el desarrollo de sistemas de reconocimiento de voz de alta precisión, capaces de transcribir audio en texto con gran fluidez. Uno de los principales modelos para esta tarea es *Whisper* el cual fue desarrollado por OpenAI. Este modelo se basa en la arquitectura *Transformer* y utiliza aprendizaje supervisado y multitarea para lograr una precisión y robustez excepcionales en una amplia gama de condiciones acústicas.\n",
    "\n",
    "`MATERIAL COMPLEMENTARIO - VIDEOTUTORIAL`: ejemplo en `Speech2Text`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e021c-c7be-4c74-9d8c-dcd03df0c2b4",
   "metadata": {},
   "source": [
    "### Aprendizaje por refuerzo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
