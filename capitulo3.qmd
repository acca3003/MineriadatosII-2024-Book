---
  execute:
    eval: false
  code-block-bg: true
  code-block-border-color: red
  code-block-border-left: "#31BAE9"
  code-line-numbers: true
  code-block-font-size: 14
---

# Algoritmos Genéticos

Buenas referencias https://repository.urosario.edu.co/server/api/core/bitstreams/7ae959ec-81de-435b-aca4-e9bb365e4894/content

Buena documentación (graficos)

https://www.cs.us.es/\~fsancho/Blog/posts/Algoritmos_Geneticos.md.html

http://www.robolabo.etsit.upm.es/asignaturas/irin/transparencias/AG.pdf

http://www.sc.ehu.es/ccwbayes/docencia/mmcc/docs/temageneticos.pdf

https://sci2s.ugr.es/sites/default/files/files/Teaching/GraduatesCourses/Bioinformatica/Tema%2006%20-%20AGs%20I.pdf

Libros de Algoritmos Genéticos



Individuo o Cromosoma Compuesto de Genes Codificación de genes (Binaria, Entera, Real)

## Introducción

Los **algoritmos genéticos**, o también llamados **algoritmos evolutivos** es un método bastante común en minería de datos. Se inspiran en el **proceso natural de selección y evolución** tal y como se describe por la teoría evolucionista de la selección natural postulada por **Darwin** [@darwin1859].

Los **principios** sobre los que se asientan los algoritmos genéticos son:

-   Los individuos **mejor adaptados** al entorno son aquellos que tienen una probabilidad mayor de **sobrevivir** y, por ende, de **reproducirse**.

-   Los descendientes **heredan** características de sus progenitores.

-   De forma esporádica y natural se producen **mutaciones** en el material genético de algunos individuos, provocando cambios permanentes.

Los algoritmos genéticos se empezaron a estudiar sobre los años 60 a partir del trabajo de Fogel [@fogel1966] (donde los organismos eran máquinas de esados finitos), siguiendo con los trabajos de Rechenberg [@rechenberg1973] (se establecen estrategias de selección) y principalmente de Holland [@holland1975] (se estableció el nombre de **Algoritmos Genéticos**).

Los algoritmos genéticos son adecuados para obtener buenas aproximaciones en **problemas de búsqueda, aprendizaje y optimización** [@marczyk2004].

De forma esquemática un algoritmo genético es una **función matemática** que tomando como entrada unos individuos iniciales (**población origen**) selecciona aquellos **ejemplares** (también llamados individuos o cromosomas) que **recombinándose** por algún método generarán como resultado la **siguiente generación**. Esta función se aplicará de forma **iterativa** hasta verificar alguna condición de parada, bien pueda ser un número máximo de iteraciones o bien la obtención de un individuo que cumpla unas restricciones iniciales.

**Condiciones para la aplicación de los Algoritmos Genéticos**

No es posible la aplicación en toda clase de problemas de los algoritmos genéticos. Para que estos puedan aplicarse, los problemas deben cumplir las siguientes condiciones:

-   El **espacio de búsqueda** [^Recordemos que cualquier método de Data Mining se puede asimilar como una búsqueda en el espacio solución, es decir, el espacio formado por todas las posibles soluciones de un problema] debe estar acotado, por tanto ser **finito**.

-   Es necesario poseer una **función** de aptitud, que denominaremos **fitness**, que evalúe cada solución (individuo) indicándonos de forma cuantitativa cuán buena o mala es una solución concreta.

-   Las **soluciones** deben ser **codificables** en un lenguaje comprensible para un **ordenador**, y si es posible de la forma más **compacta** y abreviada posible.


Habitualmente, la segunda condición es la más complicada de conseguir, para ciertos problemas es trivial la función de fitness (por ejemplo, en el caso de la búsqueda del máximo de una función) no obstante, en la vida real a veces es muy complicada de obtener y, habitualmente, se realizan conjeturas evaluándose los algoritmos con varias funciones de fitness.

**Ventajas e inconvenientes**

**Ventajas**

-   No necesitan ningún conocimiento particular del problema sobre el que trabajan, únicamente cada ejemplar debe representar una posible solución al problema.

-   Es un algoritmo admisible, es decir, con un número de iteraciones suficiente son capaces de obtener la solución óptima en problemas de optimización.

-   Los algoritmos genéticos son bastante robustos frente a falsas soluciones ya que al realizar una inspección del espacio solución de forma no lineal (por ejemplo, si quisiéramos obtener el máximo absoluto de una función) el algoritmo no recorre la función de forma consecutiva por lo que no se ve afectada por máximos locales.

-   Altamente paralelizable, es decir, ya que el cálculo no es lineal podemos utilizar varias máquinas para ejecutar el programa y evaluar así un mayor número de casos.

-   Pueden ser incrustrables en muchos algoritmos de data mining para formar modelos híbridos. Por ejemplo para seleccionar el número óptimo de neuronas en un modelo de Perceptrón Multicapa.

**Inconvenientes**

-   Su coste computacional puede llegar a ser muy elevado, si el espacio de trabajo es muy grande.

-   En el caso de que no se haga un correcto ajuste de los parámetros pueden llegar a caer en una situación de dominación en la que se produce un bucle infinito ya que unos individuos dominan sobre los demás impidiendo la evolución de la población y por tanto inhiben la diversidad biológica.

-   Puede llegar a ser muy complicado encontrar una función de evaluación de cada uno de los individuos para seleccionar los mejores de los peores.

## Fundamentos teóricos

A continuación, se explican los conceptos básicos de los algoritmos genéticos.

### Codificación de los datos

Cada **individuo o cromosoma** está formado por unos cuantos **genes**. Para nuestro caso vamos a establecer que los indiduos tienen un único cromosoma con una cierta cantidad de genes. Estos genes los consideramos como la cantidad mínima de información que se puede transferir. Los genes se pueden agrupar en **características o rasgos** que nos podrían ayudar en la resolución de ciertos problemas. 

Estos individuos con sus genes los tenemos que representar de forma que podamos codificar esa información.

![Representación de un cromosoma](imagenes/capitulo3/cromosoma.png){#fig-cromosoma}

Los principales métodos de representación son: 

-   **Binaria:** Los individuos/cromosomas están representados por una serie de genes que son bits ( valores 0 ó 1).

-   **Entera:** Los individuos/cromosomas están representados por una serie de genes que son números enteros.

-   **Real:** Los individuos/cromosomas están representados por una serie de genes que son números reales en coma flotante.

-   **Permutacional:** Los individuos/cromosomas están representados por una serie de genes que son permutaciones de un conjunto de elementos. Se usan en aquellos problemas en los que la secuencia u orden es importante.

-   **Basada en árboles:** Los individuos/cromosomas están representados por una serie de genes que son estructuras jerárquicas.

![Diferentes representaciones](imagenes/capitulo3/representaciones_individuo.png){#fig-representaciones-individuo}

El primer paso para conseguir que un ordenador procese unos **datos** es conseguir **representarlos** de una forma apropiada. En primer término, para codificar los datos, es necesario separar las posibles configuraciones posibles del dominio del problema en un **conjunto** de **estados** **finito**.

Una vez obtenida esta clasificación el objetivo es representar cada **estado** de **forma** **unívoca** con una cadena (compuesta en la mayoría de casos por unos y ceros).

A pesar de que cada estado puede codificarse con alfabetos de diferente cardinalidad[^La longitud de las cadenas que representen los posibles estados no es necesario que sea fija, representaciones como la de Kitano para representar operaciones matemáticas son un ejemplo de esto], uno de los resultados fundamentales de la teoría de algoritmos genéticos es el **Teorema del Esquema** de Holland [@holland1975], que afirma que la codificación **óptima** es aquella en la que los algoritmos tienen un alfabeto de cardinalidad, es decir el uso del **alfabeto** **binario**.


El enunciado del **Teorema del Esquema** es el siguiente: *Esquemas cortos, de bajo orden y aptitud superior al promedio reciben un incremento exponencial de representantes en generaciones subsecuentes de un Algoritmo Genético.*

Una de las ventajas de usar un alfabeto binario para la construcción de configuraciones de estados es la sencillez de los operadores utilizados para la modificación de estas. En el caso de que el alfabeto sea binario, los operadores se denominan, lógicamente, **operadores** **binarios**. Es importante destacar que variables que estén próximas en el espacio del problema deben preferiblemente estarlo en la codificación ya que la proximidad entre ellas condiciona un elemento determinante en la mutación y reproducibilidad de éstas. Es decir, dos estados que en nuestro espacio de estados del universo del problema que están consecutivos deberían estarlo en la representación de los datos, esto es útil para que cuando haya mutaciones los saltos se den entre estados consecutivos. En términos generales cumplir esta premisa mejora experimentalmente los resultados obtenidos con algoritmos genéticos.

En la práctica el factor que condiciona en mayor grado el fracaso o el **éxito** de la aplicación de algoritmos genéticos a un problema dado es una **codificación** **acorde** con los **datos**.

Otra opción muy común es establecer a cada uno de los posibles casos un **número** **natural** y luego codificar ese número en binario natural, de esta forma minimizamos el problema que surge al concatenar múltiples variables independientes en el que su representación binaria diera lugar a numerosos huecos que produjeran soluciones no válidas. 

### Algoritmo

Un algoritmo genético implementado en **pseudo código** podría ser el siguiente:

```pseudocode
#| label: alg-genetico
#| html-indent-size: "1.2em"
#| html-comment-delimiter: "//"
#| html-line-number: true
#| html-line-number-punc: ":"
#| html-no-end: false
#| pdf-placement: "htb!"
#| pdf-line-number: true


\floatname{algorithm}{Algoritmo}

\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\Procedure{Quicksort}{$A, p, r$}
  \If{$p < r$}
    \State $q = $ \Call{Partition}{$A, p, r$}
    \State \Call{Quicksort}{$A, p, q - 1$}
    \State \Call{Quicksort}{$A, q + 1, r$}
  \EndIf
\EndProcedure
\Procedure{Partition}{$A, p, r$}
 

      \State $i = i + 1$
      \State exchange

\EndProcedure
\end{algorithmic}
\end{algorithm}

```




Un posible diagrama de flujo que puede representar una posible implementación de algoritmos genéticos se muestra en la figura \ref{fig-esquema-genetico} .

![Esquema de implementación de un algoritmo genético](imagenes/capitulo3/esquema_genetico.png){#fig-esquema-genetico}

A continuación, en los siguientes apartados, se hará una descripción de las fases anteriormente expuestas:

**Inicializar Población**

Como ya se ha explicado antes, el primer paso es inicializar la población origen. Habitualmente la inicialización se hace de forma **aleatoria** procurando una **distribución** **homogénea** en los casos iniciales de prueba. No obstante, si se tiene un conocimiento más profundo del problema es posible obtener mejores resultados inicializando la población de una forma apropiada a la clase de soluciones que se esperan obtener.

**Evaluar Población**

Durante cada **iteración** (generación) cada individuo/cromosoma se decodifica convirtiéndose en un grupo de parámetros del problema y se evalúa el problema con esos datos.

Pongamos por **ejemplo** que queremos evaluar el máximo de la función $f(x)=x²$ en el intervalo $[0,1]$ y supongamos que construimos cada individuo con **6 dígitos** $(2^6=64)$ , por lo que interpretando el número obtenido en binario natural y dividiéndolo entre 64 obtendremos el punto de la función que corresponde al individuo. Evaluando dicho punto en la función que queremos evaluar ($f(x)=x²$) obtenemos lo que en nuestro caso sería el **fitness**, en este caso cuanto mayor fitness tenga un individuo, mejor valorado está y más probable es que prospere su descendencia en el futuro. No en todas las implementaciones de algoritmos genéticos se realiza una fase de evaluación de la población tal y como aquí está descrita, en ciertas ocasiones se omite y no se genera ningún fitness asociado a cada estado evaluado. La fase de selección elige los individuos a reproducirse en la próxima generación, esta selección puede realizarse por muy distintos métodos.

En el algoritmo mostrado en pseudo código anteriormente el **método** de **selección** usado depende del fitness de cada individuo. A continuación, se describen los más comunes:

**Selección elitista:** Se seleccionan los individuos con mayor fitness de cada generación. La mayoría de los algoritmos genéticos no aplican un elitismo puro, sino que en cada generación evalúan el fitness de cada uno de los individuos, en el caso de que los mejores de la anterior generación sean mejores que los de la actual éstos se copian sin recombinación a la siguiente generación.

**Selección proporcional a la aptitud:** los individuos más aptos tienen más probabilidad de ser seleccionados, asignándoles una probabilidad de selección más alta. Una vez seleccionadas las probabilidades de selección a cada uno de los individuos se genera una nueva población teniendo en cuenta éstas.

**Selección por rueda de ruleta:** Es un método conceptualmente similar al anterior. Se le asigna una probabilidad absoluta de aparición de cada individuo de acuerdo al fitness de forma que ocupe un tramo del intervalo total de probabilidad (de 0 a 1) de forma acorde a su fitness. Una vez completado el tramo total se generan números aleatorios de 0 a 1 de forma que se seleccionen los individuos que serán el caldo de cultivo de la siguiente generación.

**Selección por torneo:** se eligen subgrupos de individuos de la población, y los miembros de cada subgrupo compiten entre ellos. Sólo se elige a un individuo de cada subgrupo para la reproducción.

**Selección por rango:** a cada individuo de la población se le asigna un rango numérico basado en su fitness, y la selección se basa en este ranking, en lugar de las diferencias absolutas en el fitness. La ventaja de este método es que puede evitar que individuos muy aptos ganen dominancia al principio a expensas de los menos aptos, lo que reduciría la diversidad genética de la población y podría obstaculizar la búsqueda de una solución aceptable. Un ejemplo de esto podría ser que al intentar maximizar una función el algoritmo genético convergiera hacía un máximo local que posee un fitness mucho mejor que el de sus congéneres de población lo que haría que hubiera una dominancia clara con la consecuente desaparición de los individuos menos aptos (con peor fitness).

**Selección generacional**: la descendencia de los individuos seleccionados en cada generación se convierte en la siguiente generación. No se conservan individuos entre las generaciones.

**Selección por estado estacionario:** la descendencia de los individuos seleccionados en cada generación vuelve al acervo genético preexistente, reemplazando a algunos de los miembros menos aptos de la siguiente generación. Se conservan algunos individuos entre generaciones.

**Búsqueda del estado estacionario:** Ordenamos todos los genes por su fitness en orden decreciente y eliminamos los últimos m genes, que se sustituyen por otros m descendientes de los demás. Este método tiende a estabilizarse y converger.

**Selección jerárquica:** los individuos atraviesan múltiples rondas de selección en cada generación. Las evaluaciones de los primeros niveles son más rápidas y menos discriminatorias, mientras que los que sobreviven hasta niveles más altos son evaluados más rigurosamente. La ventaja de este método es que reduce el tiempo total de cálculo al utilizar una evaluación más rápida y menos selectiva para eliminar a la mayoría de los individuos que se muestran poco o nada prometedores, y sometiendo a una evaluación de aptitud más rigurosa y computacionalmente más costosa sólo a los que sobreviven a esta prueba inicial.

**Recombinación**.

**Recombinación** también llamada **Cross-over o reproducción**. La recombinación es el operador genético más utilizado y consiste en el **intercambio** de **material** **genético** entre **dos** **individuos** al azar (pueden ser incluso entre el mismo elemento). El material genético se intercambia entre **bloques**. Gracias a la presión selectiva[^ Presión Selectiva es la fuerza a la que se ven sometido naturalmente los genes con el paso del tiempo. Con el sucesivo paso de las generaciones los genes menos útiles estarán sometidos a una mayor presión selectiva produciéndose la paulatina desaparición de estos] irán predominando los mejores bloques génicos.



Existen diversos **tipos** de **cross-over:**

**Cross-over de 1 punto.** Los cromosomas se cortan por 1 punto y se intercambian los dos bloques de genes.

**Cross-over de n-puntos.** Los cromosomas se cortan por n puntos y el resultado se intercambia.

**Cross-over uniforme.** Se genera un patrón aleatorio en binario, y en los elementos que haya un 1 se realiza intercambio genético.

**Cross-over especializados.** En ocasiones, el espacio de soluciones no es continuo y hay soluciones que a pesar de que sean factibles de producirse en el gen no lo son en la realidad, por lo que hay que incluir restricciones al realizar la recombinación que impidan la aparición de algunas combinaciones.

::: {#fig-crossover layout-ncol=3}

![Cross-over 1 punto](imagenes/capitulo3/cross-over1.png){#fig-crossover1}

![Cross-over n puntos](imagenes/capitulo3/cross-overN.png){#fig-crossoevern}

![Cross-over uniforme](imagenes/capitulo3/cross-over-uniforme.png){#fig-crossover-uniforme}

Cross-Over
:::


**Mutación**.

Este fenómeno, generalmente muy raro en la naturaleza, se modela de la siguiente forma: cuando se genera un hijo se examinan uno a uno los genes del mismo y se genera un coeficiente aleatorio para cada uno. En el caso de que algún coeficiente supere un cierto umbral se modifica dicho gen. Modificando el umbral podemos variar la probabilidad de la mutación. Las mutaciones son un mecanismo muy interesante por el cual es posible generar nuevos individuos con rasgos distintos a sus predecesores.

Los **tipos** de **mutación** más conocidos son:
       




-   **Mutación de gen**: existe una única probabilidad de que se produzca una mutación de algún gen De producirse, el algoritmo toma aleatoriamente un gen, y lo invierte.

-   **Mutación multigen:** cada gen tiene una probabilidad de mutarse o no, que es calculada en cada pasada del operador de mutación multigen.

-   **Mutación de intercambio:** Se intercambia el contenido de dos genes aleatoriamente.

-   **Mutación de barajado:** existe una probabilidad de que se produzca una mutación. De producirse, toma dos genes aleatoriamente y baraja de forma aleatoria los genes, según hubiéramos escogido, comprendidos entre los dos.

::: {#fig-crossover layout-ncol=2}

![Mutacion gen](imagenes/capitulo3/mutacion-gen.png){#fig-mutacion-gen}

![Mutacion multigen](imagenes/capitulo3/mutacion-multigen.png){#fig-mutacion-multigen}

![Mutacion intercambio](imagenes/capitulo3/mutacion-intercambio.png){#fig-mutacion-intercambio}

![Mutacion barajado](imagenes/capitulo3/mutacion-barajado.png){#fig-mutacion-barajado}

Mutación
:::

Estos ejemplos de **mutaciones** han sido ilustradas usando una representación binaria de los datos, en caso de tener una representación **entera** al hacer la mutación no cambiaríamos de 0 a 1 o viceversa, sino que se elegiría al azar un entero de los posibles valores que tenemos para ese gen. En el caso de una representación **real** se podría pensar en al mutación de un gen como la selección de un número real entre unos valores dados mediante una **distribución uniforme** o incluso una **distribución normal**. Para profundizar en operadores sobre disintos tipos de representaciones puedes consultar [@
Eiben2015]

**Condición de finalización**

Una vez que se ha generado la nueva población se evalúa la misma y se selecciona a aquel individuo o aquellos que por su fitness se consideran los más aptos.
Podemos tener definido un umbral del valor de fitness que queremos alcanzar o simplemente definir el número de iteraciones que queremos que se realicen.

### Otros Operadores

Los operadores descritos anteriormente suelen ser operadores **generalistas** (aplicables y de hecho aplicados a todo tipo de problemas), sin embargo, para ciertos contextos suele ser más recomendable el uso de operadores específicos para realizar un recorrido por el espacio de solución más acorde a la solución buscada.

**Modificadores de la longitud de los individuos**. En ocasiones las soluciones no son una combinación de todas las variables de entrada, en estas ocasiones los individuos deberán tener una longitud variable[^En muchas ocasiones, se realizan estudios de minería de datos sobre todos los datos existentes, encontrándose en ellos variables espúreas, es decir, variables que no aportan nada de información para el problema evaluado]. Lógicamente, en este tipo de casos, es necesario modificar la longitud de los individuos, para ello haremos uso de los operadores añadir y quitar, que añadirán o quitarán a un individuo un trozo de su carga génica (es decir, un trozo de información).


### Parámetros necesarios al aplicar Algoritmos Genéticos

Cualquier algoritmo genético necesita ciertos parámetros que deben fijarse antes de cada ejecución, como:

**Tamaño de la población:** Determina el tamaño máximo de la población a obtener. En la práctica debe ser de un valor lo suficientemente grande para permitir diversidad de soluciones e intentar llegar a una buena solución, pero siendo un número que sea computable en un tiempo razonable.

**Condición de terminación:** Es la condición de parada del algoritmo. Habitualmente es la convergencia de la solución (si es que la hay), un número prefijado de generaciones o una aproximación a la solución con un cierto margen de error.

**Individuos que intervienen en la reproducción de cada generación:** se especifica el porcentaje de individuos de la población total que formarán parte del acervo de padres de la siguiente generación. Esta proporción es denominada proporción de cruces.

**Probabilidad de ocurrencia de una mutación:** En toda ejecución de un algoritmo genético hay que decidir con qué frecuencia se va a aplicar la mutación. Se debe de añadir algún parámetro adicional que indique con qué frecuencia se va a aplicar dentro de cada gen del cromosoma. La frecuencia de aplicación de cada operador estará en función del problema; teniendo en cuenta los efectos de cada operador, tendrá que aplicarse con cierta frecuencia o no. Generalmente, la mutación y otros operadores que generen diversidad se suelen aplicar con poca frecuencia; la recombinación se suele aplicar con frecuencia alta.

Cada implementación de algoritmo tendrá sus propios parámetros que permitirán personalizar la ejecución de nuestro problema concreto.

::: {.callout-important title="Recordad"}
Los algoritmos genéticos es uno de los **enfoques más originales** en data mining. Su sencillez, combinada con su flexibilidad les proporciona una **robustez** que les hace adecuados a infinidad de problemas. No obstante, su **simplicidad** y sobre todo independencia del problema hace que sean algoritmos poco específicos. Recorriendo este capítulo hemos visto los numerosos parámetros y métodos aplicables a los algoritmos genéticos que nos ayudan a realizar una adaptación de los algoritmos genéticos más concreta a un problema. En definitiva, la implementación de esquemas evolutivos tal y como se describen en biología podemos afirmar que funciona.
:::



## Casos de uso

Para los **Algoritmos genéticos** tenemos 3 grandes grupos de casos de uso:

- **Optimización de Funciones**
  - Podemos buscar máximo o mínimos de funciones.
  
- **Optimización Cominatorial**
  - TSP (Travel Salesman Problem) Problema del viajante
  - VRP (Vechicule Routing Problem) Problema de rutas de vehículos

- **Optimización Machine Learning**
  - Hiperparámetros
  - Selección de variables
  - Network Architecture

Vamos a ver cómo se podrían abordar algunos de estos casos de uso:

### Selección de Variable


El objetivo del ejemplo es ver cómo podemos usar un algoritmo genético para hacer una **selección de variables**, quedándonos sólo con unas pocas.

Supongamos que tenemos un **dataset** que es un problema de **clasificación** con **3 clases**, cuenta con **1500 muestras** y **14 variables** explicativas. 

Tendremos que, para el algoritmo genético, nuestro cromosoma o individuo será un **vector** de tamaño 14 (**14 genes**), que representa las **14 variables** del dataset que hemos preparado.

En la imagen @fig-poblacion mostramosla población de 100 individuos en una iteración N.

![Población en iteración N](imagenes/capitulo3/poblacion.png){#fig-poblacion}

**Función Fitness** (Evaluación)

Cuando estamos trabajando con selección de variables, el objetivo es conseguir el conjunto de variables que mejor modelo construyan según nuestro dataset. En este caso, al ser un problema de **clasificación**, veremos cual es la combinación de variables que nos da **menos errores al clasificar**.

Nuestra función fitness deberá seguir estos **pasos**:

\- Recibe una **variable** que tiene el tamaño del numero de variables (el tamaño del cromosoma) que hay en el dataframe (en nuestro caso 14) de datos.

-   Los valores son **1** si esa variable se va a **usar** y **0** si **no** se va a **usar**.

\- Se construye un **modelo**, en este caso usamos **LDA** (Análisis Discriminante Lineal) con las **variables** que tienen **valor 1**.

\- Calculamos el **error** que queremos minimizar (número de fallos)

\- Para este caso del LDA cogemos los valores **\$posterior** que nos dan la probabilidad de cada clase para cada entrada de la muestra

\- Calculamos cual es el **máximo** y así le asignamos esa **clase** como su solución. También podríamos coger directamente el valor de \$class con la clase dada como predicción.

\- Verificamos cuantos hemos fallado y lo dividimos por el número de muestras para ver el **porcentaje** de **fallos**

\- Devolvemos el **porcentaje de fallos**. El resultado de la ejecución del algoritmo evolutivo nos dará un objeto del que tendremos que obtener que variables son las que queremos usar.

@fig-poblacion_final

![Población Final](imagenes/capitulo3/poblacion_final.png){#fig-poblacion_final fig-align="center"}

Una vez que nuestro algoritmo pare, deberíamos tener la población que mejor se ha adaptado según el fitness que habíamos definido.

En nuestro caso estarán por ejemplo las 100 mejores combinaciones de variables, que dan el menor error al clasificar. De esta manera si para cada variable contamos cuantas veces ha salido en cada elemento de la población, sabremos cuantas veces se ha usado en las combinaciones de variables de esta última iteración (que es la mejor hasta ese momento). Con lo cual podremos saber cuales han sido las **variables** **más** **usadas** en la población final.

El objeto **modelo_evolutivo**, que nos devuelve rbga.bin, tiene una variable **population** de dimensiones tamaño_población x numero_variables , en nuestro caso de 100x14, que tiene la información de la población de la **última iteración del algoritmo**, que en un principio debería ser la mejor. Este population contiene para cada fila (elemento en la población), 0 o 1 en la posición que corresponde a cada variable.

Para ver cuales son las variables que más se han usado tenemos que sumar por columnas y ese dato nos dará para cada columna (corresponde con una variable) la cantidad de veces que se ha usado en esta población. Una vez tenemos estos datos ya podemos quedarnos con el número de variables que deseemos cogiendo las que más alto valor tienen.




@fig-frecuencia_variables

Imagen \ref{fig-frecuencia_variables}

![Frecuencia de las Variables](imagenes/capitulo3/frecuencia_variables.png){#fig-frecuencia_variables}


### Entrenamiento de Red Neuronal

Otro de los casos de uso sobre los que se podría trabajar con un **Algoritmo Genético** es el entrenamiento de una Red Neuronal. La forma estandard de entrenar una Red Neuronal es lo que se denomina el Backpropagation, que mediante el uso de las estrategias del **Descenso del Gradiente** se consigue optimizar los parámetros de la Red Neuronal.

Cuando entrenamos una Red Neuronal, lo que conseguimos es obtener una serie de valores de los **pesos** de la Red Neuronal. Estos pesos combinados con las funciones de activación serán los que nos darán el resultado de salida a partir de los datos de entrada.

Supongamos que tenemos una **Red Neuronal** con **500** parámetros distribuidos en las diferentes capas ocultas del mismo.

Tendremos que, para el algoritmo genético, nuestro cromosoma o individuo será un **vector** de tamaño 500 (**500 genes**), que representan los **500 valores** de los pesos de la Red Neuronal. En este caso los valores del vector tendrán una **representación real**.

A cada uno de estos posibles valores reales lo deberemos acotar en un rango de valores, que podría ser *(-2.0 , 2.0 ) de forma que cuando cuando se generen los valores aleatorios de una población, cada dato deberá partir de este rango.

En la imagen @fig-poblacion mostramos la población de 100 individuos en una iteración N.

![Población en iteración N](imagenes/capitulo3/entrenamiento_red_poblacion.png){#fig-poblacion_entrenamiento_red}

**Función Fitness** (Evaluación)

Cuando estamos trabajando con el Entrenamiento de una Red Neuronal, el objetivo es conseguir la red neuronal que mejor valor de la **función de pérdida** de la red neuronal tenga.

Nuestra función fitness deberá seguir estos **pasos**:

\- Recibe una **variable** que tiene el tamaño del numero de pesos en la red neuronal (el tamaño del cromosoma), en nuestro caso 500.

- Los valores serán un número real

\- Se cogen estos pesos y se asignan a la Red Neuronal.

- Una vez tenemos la red neuronal, pasamos nuestros datos de entrenamiento y evaluamos el modelo obteniendo el valor de la función de pérdida.

\- Devolvemos el **valor de la función de pérdida**.


@fig-poblacion_final

![Población Final](imagenes/capitulo3/entrenamiento_red_poblacion_final.png){#fig-poblacion_final_entrenamiento_red fig-align="center"}


Una vez que nuestro algoritmo pare, deberíamos tener la población que mejor se ha adaptado según el fitness que habíamos definido.

Seleccionamos aquella que menor valor de función de pérdida nos haya dado.




### Arquitecura de RedNeuronal

Siguiendo con las redes neuronales, otro de los casos de uso sobre los que se podría trabajar con un **Algoritmo Genético** es la **Arquitectura de Red** de la Red Neuronal. En el sentido de poder definir cuantos nodos por cada capa oculta podemos tener, para conseguir una buena Red Neuronal. En ese caso estamos pensando en una red neuronal usada para datasets clásicos de datos y no de imágenes.



Cuando entrenamos una Red Neuronal, lo que conseguimos es obtener una serie de valores de los **pesos** de la Red Neuronal. Estos pesos combinados con las funciones de activación serán los que nos darán el resultado de salida a partir de los datos de entrada.

Supongamos que tenemos una **Red Neuronal** con **500** parámetros distribuidos en las diferentes capas ocultas del mismo.

Tendremos que, para el algoritmo genético, nuestro cromosoma o individuo será un **vector** de tamaño 500 (**500 genes**), que representan los **500 valores** de los pesos de la Red Neuronal. En este caso los valores del vector tendrán una **representación real**.

A cada uno de estos posibles valores reales lo deberemos acotar en un rango de valores, que podría ser *(-2.0 , 2.0 ) de forma que cuando cuando se generen los valores aleatorios de una población, cada dato deberá partir de este rango.

En la imagen @fig-poblacion mostramos la población de 100 individuos en una iteración N.

![Población en iteración N](imagenes/capitulo3/entrenamiento_red_poblacion.png){#fig-poblacion_entrenamiento_red}

**Función Fitness** (Evaluación)

Cuando estamos trabajando con el Entrenamiento de una Red Neuronal, el objetivo es conseguir la red neuronal que mejor valor de la **función de pérdida** de la red neuronal tenga.

Nuestra función fitness deberá seguir estos **pasos**:

\- Recibe una **variable** que tiene el tamaño del numero de pesos en la red neuronal (el tamaño del cromosoma), en nuestro caso 500.

- Los valores serán un número real

\- Se cogen estos pesos y se asignan a la Red Neuronal.

- Una vez tenemos la red neuronal, pasamos nuestros datos de entrenamiento y evaluamos el modelo obteniendo el valor de la función de pérdida.

\- Devolvemos el **valor de la función de pérdida**.


@fig-poblacion_final

![Población Final](imagenes/capitulo3/entrenamiento_red_poblacion_final.png){#fig-poblacion_final_entrenamiento_red fig-align="center"}


Una vez que nuestro algoritmo pare, deberíamos tener la población que mejor se ha adaptado según el fitness que habíamos definido.

Seleccionamos aquella que menor valor de función de pérdida nos haya dado.


## Algoritmos genéticos con R
### Paquetes para usar en R
### Selección de variables
### Entrenamiento de Red Neuronal

## Algoritmos genéticos en Python
### Paquetes para usar en Python
### Optimiación de funciones
### Entrenamiento de Red Neuronal

``` python
import os import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns

from genetic_selection import GeneticSelectionCV

from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split from sklearn.metrics import confusion_matrix
```

**Cargar datos de trabajo**

``` python

os.chdir('C:/Users/p_san/Desktop/Máster_2020/Módulo_5') #directorio datos=pd.read_csv('german_credit.csv',encoding = 'ISO-8859-1', index_col=None)
```

Todas las variables son categóricas salvo:

duration

credit_amount

residence_since

age

existing_credits

num_dependents

Conversión a variables categóricas

``` python
datos\['checking_status'\]=datos\['checking_status'\].astype('category') datos\['credit_history'\]=datos\['credit_history'\].astype('category') datos\['purpose'\]=datos\['purpose'\].astype('category') datos\['savings_status'\]=datos\['savings_status'\].astype('category') datos\['employment'\]=datos\['employment'\].astype('category') datos\['personal_status'\]=datos\['personal_status'\].astype('category') datos\['other_parties'\]=datos\['other_parties'\].astype('category') datos\['property_magnitude'\]=datos\['property_magnitude'\].astype('category') datos\['other_payment_plans'\]=datos\['other_payment_plans'\].astype('category') datos\['housing'\]=datos\['housing'\].astype('category') datos\['job'\]=datos\['job'\].astype('category') datos\['property_magnitude'\]=datos\['property_magnitude'\].astype('category') datos\['own_telephone'\]=datos\['own_telephone'\].astype('category') datos\['foreign_worker'\]=datos\['foreign_worker'\].astype('category') datos\['class'\]=datos\['class'\].astype('category')
```

La variable class es una variable reservada en diferentes módulos de Python -\> reemplazar por por target

``` python
datos.rename(columns={'class': 'target'}, inplace=True) datos\['target'\]=np.where(datos\['target'\]=='good', 0, 1) \# cambio en la codificación por sencillez en el preprocesado
```

Definición de la muestra de trabajo

``` python
datos_entrada=datos.drop('target', axis=1) \# Datos de entrada datos_entrada= pd.get_dummies(datos_entrada, drop_first=True) #conversión a variables dummy
```

datos de salida

``` python
respuesta=datos.loc\[:, 'target'\]
```

Escalado de las variables, partición de la muestra y Cross Validation

``` python
seed=123 \# Escalado de los datos de entrada x_esc=StandardScaler().fit_transform(datos_entrada) x_esc=pd.DataFrame(x_esc, columns=datos_entrada.columns)
```

Partición de la muestra

test_size=0.3 #muestra para el test x_train, x_test, y_train, y_test = train_test_split(x_esc,respuesta, test_size=test_size, random_state=seed, stratify=respuesta) Usando un modelo Cart from sklearn.tree import DecisionTreeClassifier cart=DecisionTreeClassifier(max_depth=5, random_state=seed) cart_algoritmo_gen=GeneticSelectionCV(cart, cv=5, \# 5 particiones verbose=0, \# no se muestran los resultados en la pantalla scoring="roc_auc", \# ejemplo métrica para evaluar max_features=15, \# número de variables máximas en la selección de\
\# características n_population=50, \# tamaño de la población crossover_proba=0.5, \# probabilidad de cruce entre parejas de genes mutation_proba=0.2, #probabilidad de mutación n_generations=40, #número de generaciones crossover_independent_proba=0.5, \# prob. cruce para genes \# independientes mutation_independent_proba=0.05, \# prob. mutación de genes \# independientes tournament_size=3, #tamaño de los grupos n_gen_no_change=10, \# genes que se mantienen -\> no pasan a \# la segunda generación caching=True, n_jobs=1)

cart_algoritmo_gen=cart_algoritmo_gen.fit(x_train, y_train)\
ajuste del modelo usando algoritmo genéticos para la selección de variables \# Variables Seleccionadas print('Num. Var:', cart_algoritmo_gen.n_features\_) \# print(cart_algoritmo_gen.support\_)\
\# Resultados matriz numpy -\> mala visualización. Los resultados se \# convierten a df de pandas df=pd.DataFrame(cart_algoritmo_gen.support\_, columns=\['Variables'\], index=x_train.columns) df=df.loc\[\~df\['Variables'\].isin(\[False\])\] #se elimina del df las variables no seleccionadas por el algoritmo list(df.index) \# variables seleccionadas por el algoritmo

Num. Var: 9 \['checking_status_0\<=X\<200', 'checking_status\_\<0', "credit_history\_'critical/other existing credit'", "purpose\_'used car'", 'savings_status\_\>=1000', "personal_status\_'male single'", 'other_parties_guarantor', 'other_payment_plans_stores', 'job_skilled'\]

Resultados test - predicción & Matriz de confusión (modelo CART con selección de variables a través de Algoritmos Genéticos)

pred=cart_algoritmo_gen.predict(x_test)

confusion_matrix(y_test, pred) \# Matriz de confusión

array(\[\[173, 37\], \[ 46, 44\]\], dtype=int64)

