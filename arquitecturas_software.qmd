## Principales arquitecturas y software de Deep Learning

Actualmente existen muchos tipos de estructuras de redes neuronales artificiales dado que logran resultados extraordinarios en muchos campos del conocimiento. Los primeros √©xitos en el aprendizaje profundo se lograron a trav√©s de las investigaciones y trabajos de Geoffre Hinton (2006) que introduce las Redes de Creencia Profunda en cada capa de la red de una M√°quina de Boltzmann Restringida (RBM) para la asignaci√≥n inicial de los pesos sin√°pticos. Hace tiempo que se est√° trabajando con arquitecturas como los Autoencoders, Hinton y Zemel (1994), las RBMs de Hinton y Sejnowski (1986) y las DBNs (Deep Belief Networks), Hinton et al. (2006) y otras como las redes recurrentes y convolucionales. Estas t√©cnicas constituyen en s√≠ mismas arquitecturas de redes neuronales, aunque tambi√©n algunas de ellas, como se ha afirmado en la introducci√≥n, se est√°n empleando para inicializar los pesos de arquitecturas profundas de redes neuronales supervisadas con conexiones hacia adelante. Las principales arquitecturas de deep learning se resumen en la siguiente figura. Figura 65. modelos de redes neuronales seg√∫n tipo de aprendizaje

Vamos a describir de forma somera las principales arquitecturas dado que posteriormente se desarrollan m√°s ampliamente en este ep√≠grafe o se tratan en docuemento adjunto que se acompa√±a en este m√≥dulo **Convolutional Neural Network** Tal vez los modelos m√°s utilizados actualmente en el campo del Deep Learning sean las redes neuronales convolucionales, denominadas en ingl√©s Convolutional Neural Networks (CNN). El objetivo de las redes CNN es aprender caracter√≠sticas de orden superior utilizando la operaci√≥n de convoluci√≥n. Estas estructuras de redes neuronales son especialmente eficaces para clasificar y segmentar im√°genes, en general, son notablemente eficaces en tareas de visi√≥n artificial. Las CNN son una modificaci√≥n del perceptr√≥n multicapa explicado en un m√≥dulo anterior. Este modelo es muy similar al trabajo que ejecuta el cerebro humano: las neuronas se corresponden a campos receptivos similares a como lo realizan las neuronas en la corteza visual de nuestro cerebro. Esta arquitectura ya se utiliz√≥ en 1990 donde la empresa AT & T las aplic√≥ para crear un modelo de lectura de cheques, desarroll√°ndose posteriormente muchos sistemas OCR basados en CNN. Las redes de convoluci√≥n tienen una estructura de varias capas: las capas de Convoluci√≥n que transforman los datos de entrada a trav√©s de una operaci√≥n matem√°tica llamada Convoluci√≥n y la capa de pooling, que trata de sintetizar y condensar la informaci√≥n de la capa de convoluci√≥n. Finalmente, se transforman los datos para aplicar una red densamente conectada que nos ofrece el resultado final en relaci√≥n con el objetivo que se busca. Estas redes neuronales artificiales se desarrollaron al abrigo de los concursos denominados ILSVRC (Large Scale Visual Recognition Challenge) donde aparecieron las principales aportaciones efectuadas en las redes convolucionales y que hoy podemos utilizar todos los investigadores. Algunos de las estructuras m√°s novedosas y que son modelos ya preentrenados, con estructuras de capas m√°s numerosas y que podemos integrar en nuestras aplicaciones, se denominan: LeNet-5, AlexNet, VGG, GoogLeNet y Resnet.

**Autoencoder** Los Autoencoders (AE) son uno de los tipos de redes neuronales que caen dentro del √°mbito del Deep Learning, en la que nos encontramos con un modelo de aprendizaje no supervisado. Ya se empez√≥ a hablar de AE en la d√©cada de los 80 (Bourlard and Kamp 1988), aunque es en estos √∫ltimos a√±os donde m√°s se est√° trabajando con ellos. La arquitectura de un AE es una Red Neuronal Artificial (ANN por sus siglas en ingl√©s) que se encuentra dividida en dos partes, encoder y decoder (Charte et al. 2018), (Goodfellow, Bengio, and Courville 2016). El encoder va a ser la parte de la ANN que va codificar o comprimir los datos de entrada, y el decoder ser√° el encargado de regenerar de nuevo los datos en la salida. Esta estructura de codificaci√≥n y decodificaci√≥n le llevar√° a tener una estructura sim√©trica. El AE es entrenado para ser capaz de reconstruir los datos de entrada en la capa de salida de la ANN, implementando una serie de restricciones (la reducci√≥n de elementos en las capas ocultas del encoder) que van a evitar que simplemente se copie la entrada en la salida. Algunas de sus principales aplicaciones sobre las que se est√° investigando son: ‚Ä¢ Reducci√≥n de dimensiones / Compresi√≥n de datos ‚Ä¢ B√∫squeda de im√°genes ‚Ä¢ Detecci√≥n de Anomal√≠as ‚Ä¢ Eliminaci√≥n de ruido **Redes recurrentes** En la actualidad las **redes neuronales recurrentes (Recurrent Neural Networks)** han logrado un puesto destacado en machine learning. Estas redes que no disponen de una estructura de capas, sino que permiten conexiones arbitrarias entre todas las neuronas, incluso creando ciclos. En esta arquitectura se permiten conexiones recurrentes lo que aumenta el n√∫mero de pesos o de par√°metros ajustables de la red, lo que incrementa la capacidad de representaci√≥n, pero tambi√©n la complejidad del aprendizaje. Las peculiaridades de esta red permiten incorporar a la red el concepto de temporalidad, y tambi√©n que la red tenga memoria, porque los n√∫meros que introducimos en un momento dado en las neuronas de entrada son transformados, y contin√∫an circulando por la red. Existen diferentes planteamientos de redes recurrentes, por ejemplo, son muy populares por sus aplicaciones las redes de Elmann y de Jordan. En los √∫ltimos a√±os se han popularizado las redes recurrentes denominadas Long-Short Term Memory (LSTM) que son una extension de las redes recurrentes y su caracter√≠tica principal es que amplian su memoria para registrar experiencias que han ocurrido hace mucho tiempo. Normalmente contienen tres puertas que determinan si se permite o no una nueva entrada o se elimina la informaci√≥n que llega dado que se considera no importante. Son an√°logas a una funci√≥n sigmoide lo que implica que van de 0 a 1, lo que permite incorporarlas al proceso de backpropagation. Tambi√©n se encuentran entre las redes recurrentes, las denominadas GRU (Gated Recurrent Unit) que aparecieron en 2014 y simplifican a las LSMT: son computacionalmente menos costosas y m√°s eficientes.

Boltzmann Machine y Restricted Boltzmann Machine El aprendizaje de la denominada m√°quina de Boltzmann (BM) se realiza a trav√©s de un algoritmo estoc√°stico que proviene de ideas basadas en la mec√°nica estad√≠stica. Este prototipo de red neuronal tiene una caracter√≠stica distintiva y es que el uso de conexiones sin√°pticas entre las neuronas es sim√©trico. Las neuronas son de dos tipos: visibles y ocultas. Las neuronas visibles son las que interact√∫an y proveen una interface entre la red y el ambiente en el que operan, mientras que las neuronas act√∫an libremente sin interacciones con el entorno. Esta m√°quina dispone de dos modos de operaci√≥n. El primero es la condici√≥n de anclaje donde las neuronas est√°n fijas por los est√≠mulos espec√≠ficos que impone el ambiente. El otro modo es la condici√≥n de libertad, donde tanto las neuronas ocultas como las visibles act√∫an libremente sin condiciones impuestas por el medio ambiente. Las maquinas restringidas de Boltzmann (RBM) solamente toman en cuenta aquellos modelos en los que no existen conexiones del tipo visible-visible y oculta-oculta. Estas redes tambi√©n asumen que los datos de entrenamiento son independientes y est√°n id√©nticamente distribuidos. Una forma de estimar los par√°metros de un modelo estoc√°stico es calculando la m√°xima verosimilitud. Para ello, se hace uso de los Markov Random Fiels (MRF), ya que al encontrar los par√°metros que maximizan los datos de entrenamiento bajo una distribuci√≥n MRF, equivale a encontrar los par√°metros ùúÉ que maximizan la verosimilitud de los datos de entrenamiento, Fischer e Igel (2012). Maximizar dicha verosimilitud es el objetivo que persigue el algoritmo de entrenamiento de una RBM. A pesar de utilizar la distribuci√≥n MRF, computacionalmente hablando se llega a ecuaciones inviables de implementar. Para evitar el problema anterior, las esperanzas que se obtienen de MRF pueden ser aproximadas por muestras extra√≠das de distribuciones basadas en las t√©cnicas de Markov Chain Monte Carlo Techniques (MCMC). Las t√©cnicas de MCMC utilizan un algoritmo denominado muestreo de Gibbs con el que obtenemos una secuencia de observaciones o muestras que se aproximan a partir de una distribuci√≥n de verosimilitud de m√∫ltiples variables aleatorias. La idea b√°sica del muestreo de Gibss es actualizar cada variable posteriormente en base a su distribuci√≥n condicional dado el estado de las otras variables. Deep Belief Network Una red Deep Belief Network tal como demostr√≥ Hinton se puede considerar como un "apilamiento de redes restringidas de Boltzmann". Tiene una estructura jer√°rquica que como sabemos es una de las caracter√≠sticas del deep learning. Como en el anterior modelo, esta red tambi√©n es un modelo en grafo estoc√°stico, que aprende a extraer una representaci√≥n jer√°rquica profunda de los datos de entrenamiento. Cada capa de la RBM extrae un nivel de abstracci√≥n de caracter√≠sticas de los datos de entrenamiento, cada vez m√°s significativo; pero para ello, la capa siguiente necesita la informaci√≥n de la capa anterior lo que implica el uso de las variables latentes. Estos modelos caracterizan la distribuci√≥n conjunta hk entre el vector de observaciones x y las capas ocultas, donde x=h0, es una distribuci√≥n condicional para las unidades visibles limitadas sobre las unidades ocultas que pertenecen a la RBM en el nivel k, y es la distribuci√≥n conjunta oculta visible en la red RBM del nivel superior o de salida. El entrenamiento de esta red puede ser h√≠brido, empezando por un entrenamiento no supervisado para despu√©s aplicar un entrenamiento supervisado para un mejor y m√°s √≥ptimo ajuste, aunque pueden aplicarse diferentes tipos de entrenamiento, Bengio et al. (2007) y Salakhutdinov (2014) Para realizar un entrenamiento no supervisado se aplica a las redes de creencia profunda con Redes restringidas de Boltzmann el m√©todo de bloque constructor que fue presentado por Hinton (2006) y por Bengio (2007)