# Deep Learning

## Introducci√≥n

El **deep learning o aprendizaje profundo** es un concepto amplio, un t√©rmino de moda que atiende a una realidad que cada d√≠a est√° m√°s presente entre nosotros, y que no tiene una √∫nica definici√≥n que se pueda considerar veraz, aunque podemos generalizar la definici√≥n afirmando que surge de la idea de imitar el cerebro a partir de la utilizaci√≥n de hardware y software, para crear inteligencia artificial. Este intento de imitar al cerebro se ha plasmado en lo que se conoce como redes neuronales artificiales (RNA) que est√°n dotadas de una capacidad de abstracci√≥n jer√°rquica: representan los datos de entrada en varios "niveles", a trav√©s de arquitecturas en varias capas, cada capa aprende patrones m√°s complejos seg√∫n la profundidad de √©sta, para conseguir informaci√≥n √∫til para el aprendizaje.

Podemos afirmar que el principio general del funcionamiento de una arquitectura profunda es guiar el entrenamiento de las capas intermedias utilizando aprendizaje no supervisado. Algunos de los prototipos de arquitecturas y/o algoritmos desarrollados se basan en otras arquitecturas "m√°s simples", modific√°ndolas y obteniendo una arquitectura "m√°s profunda", lo que quiere decir que en sus capas y neuronas se separan las caracter√≠sticas de un conjunto de datos de entrada de una forma jerarquizada.

Otra definici√≥n dada del aprendizaje profundo es que es un subconjunto de los algoritmos usados en machine learning, y se caracterizan por tener una **arquitectura en capas** donde cada capa aprende patrones m√°s complejos seg√∫n la profundidad de √©sta. En este sentido, existen ya muchos prototipos de redes neuronales que tienen esta caracter√≠stica, por ejemplo, las ya muy conocidas redes convolucionales o las redes recurrentes. El Perceptron Multicapa de una sola capa explicado en el m√≥dulo 5 no es considerado un m√©todo de aprendizaje profundo. El Deep Learning es una t√©cnica reciente donde a√∫n se sigue investigando y desarroll√°ndose y que surgi√≥ a partir del a√±o 2006, a√±o en el que se considera fue retomada su investigaci√≥n. El principal problema por el que se hab√≠a ralentizado su progreso es que el entrenamiento basado en el m√©todo del gradiente para redes neuronales profundas supervisadas, seg√∫n muchos investigadores, se estancaba en lo que se llama m√≠nimo local aparente, lo que significa que una red con m√°s capas ocultas, es decir una red neuronal m√°s profunda, obtiene peores resultados que una red con s√≥lo una capa oculta. Los investigadores abordaron este tema planteado a trav√©s de diferentes √≥pticas y se descubre que se obtienen resultados m√°s precisos si cada capa de la red es entrenada a trav√©s de un algoritmo de preentrenamiento no supervisado (el m√©todo del gradiente requiere que sea supervisado) Para el entrenamiento de las capas, diversos autores sugieren utilizar autoencoders o m√°quinas de Boltzmann y, una vez se hayan preentrenado las diferentes capas, se puede aplicar un criterio supervisado. En estos √∫ltimos a√±os se ha producido un r√°pido crecimiento en la cantidad de arquitecturas y/o algoritmos de entrenamiento en una RNA, incluso, variantes de ellos, las cuales siguen el concepto planteado anteriormente.

## Revisi√≥n de las Redes Neuronales

Vamos a hacer una revisi√≥n de las redes neuronales para posteriormente poder abordar los diferentes tipos de redes neuronales que se utilizan en Deep Learning. Algunos de los avances m√°s recientes en varios de los diferentes componentes que forman parte de las redes neuronales est√°n recopilados en (Gu et al. 2017) Las redes neuronales artificiales tienen sus or√≠genes en el Perceptr√≥n, que fue el modelo creado por Frank Rosenblatt en 1957 y basado en los trabajos que previamente hab√≠an realizado Warren McCullon (neurofisi√≥logo) y Walter Pitts (matem√°tico). El Perceptr√≥n est√° construido por una neurona artificial cuyas entradas y salida pueden ser datos num√©ricos, no como pasaba con la neurona de McCulloch y Pitts (eran s√≥lo datos l√≥gicos). Las neuronas pueden tener pesos y adem√°s se le aplica una funci√≥n de activaci√≥n Sigmoid (a diferencia de la usada anteriormente al Paso binario). En esta neurona nos encontramos que se realizan los siguientes c√°lculos: $$ z = \sum_{i=1}^{n}w_ix_i+b_i$$ $$\hat{y} = \delta (z)$$

donde representan los datos num√©ricos de entrada, son los pesos, es el sesgo (bias), es la funci√≥n de activaci√≥n y finalmente es el dato de salida. El modelo de perceptr√≥n es el m√°s simple, en el que hay una sola capa oculta con una √∫nica neurona. El siguiente paso nos lleva al Perceptr√≥n Multicapa donde ya pasamos a tener m√°s de una capa oculta, y adem√°s podemos tener m√∫ltiples neuronas en cada capa oculta. Cuando todas las neuronas de una capa est√°n interconectadas con todas las de la siguiente capa estamos ante una red neuronal densamente conectada. A lo largo de las siguientes secciones nos encontraremos con redes en las que no todas las neuronas de una capa se conectan con todas de la siguiente. Veamos como describir√≠amos ahora los resultados de las capas donde representan los datos de la neurona en la capa ( siendo los valores de entrada), son los pesos en la capa , es el sesgo (bias) en la capa , es la funci√≥n de activaci√≥n en la capa (puede que cada capa tenga una funci√≥n de activaci√≥n diferente), es el n√∫mero de neurona de la capa anterior que conectan con la y finalmente es el dato de salida de la capa . Es decir, en cada capa para calcular el nuevo valor necesitamos usar los valores de la capa anterior.

**Aplicaciones de las Redes Neuronales**

Cada d√≠a las redes neuronales est√°n m√°s presentes en diferentes campos y ayudan a resolver una gran variedad de problemas. Podr√≠amos pensar que de forma m√°s b√°sica una red neuronal nos puede ayudar a resolver problemas de regresi√≥n y clasificaci√≥n, es decir, podr√≠amos considerarlo como otro modelo m√°s de los existentes que a partir de unos datos de entrada somos capaces de obtener o un dato num√©rico (o varios) para hacer una regresi√≥n (calcular en precio de una vivienda en funci√≥n de diferentes valores de la misma) o que somos capaces de conseguir que en funci√≥n de los datos de entrada nos deje clasificada una muestra (decidir si conceder o no una hipoteca en funci√≥n de diferentes datos del cliente). Si los datos de entrada son im√°genes podr√≠amos estar usando las redes neuronales como una forma de identificar esa imagen: ‚Ä¢ Identificando que tipo de animal es ‚Ä¢ Identificando que se√±al de tr√°fico es ‚Ä¢ Identificando que tipo de fruta es ‚Ä¢ Identificando que una imagen es de exterior o interior de una casa ‚Ä¢ Identificando que es una cara de una persona ‚Ä¢ Identificando que una imagen radiogr√°fica represente un tumor maligno ‚Ä¢ Identificando que haya texto en una imagen Luego podr√≠amos pasar a revolver problemas m√°s complejos combinando las capacidades anteriores: ‚Ä¢ Detectar los diferentes objetos y personas que se encuentran en una imagen ‚Ä¢ Etiquedado de escenas (aula con alumnos, partido de futbol, etc...) Despu√©s podr√≠amos dar el paso al video que lo podr√≠amos considerar como una secuencia de im√°genes: ‚Ä¢ Contar el n√∫mero de personas que entran y salen de una habitaci√≥n ‚Ä¢ Reconocer que es una carretera ‚Ä¢ Identificar las se√±ales de tr√°fico ‚Ä¢ Detectar si alguien lleva un arma ‚Ä¢ Seguimiento de objetos ‚Ä¢ Detecci√≥n de estado/actitud de una persona ‚Ä¢ Reconocimiento de acciones (interpretar lenguaje de signos, interpretar lenguaje de banderas) ‚Ä¢ Veh√≠culos inteligentes Si los datos de entrada son secuencias de texto ‚Ä¢ Sistemas de traducci√≥n ‚Ä¢ Chatbots (resoluci√≥n de preguntas a usuarios) ‚Ä¢ Conversi√≥n de texto a audio Si los datos de entrada son audios ‚Ä¢ Sistemas de traducci√≥n ‚Ä¢ Altavoces inteligentes ‚Ä¢ Conversi√≥n de audio a texto

A continuaci√≥n, pasamos a revisar diferentes elementos de las redes neuronales que suelen ser comunes a todos los tipos de redes neuronales.

**Datos**

Cuando se trabaja con redes neuronales necesitamos representar los valores de las variables de entrada en forma num√©rica. En una red neuronal todos los datos son siempre num√©ricos. Esto significa que todas aquellas variables que sean categ√≥ricas necesitamos convertirlas en num√©ricas. Adem√°s, es muy conveniente normalizar los datos para poder trabajar con valores entre 0 y 1, que van a ayudar a que sea m√°s f√°cil que se pueda converger a la soluci√≥n. Es importante que los datos se√°n n√∫meros en coma flotante, sobre todo si se van a trabajar con GPUs (Graphics Process Units), ya que permitir√°n hacer un mejor uso de los multiples cores que les permiten operar en coma flotante de forma paralela. Actualmente, hay toda una serie de mejoras en las GPUs que permite aumentar el rendimiento de las redes neuronales como son el uso de operaciones en FP16 (Floating Point de 16 bits en lugar de 32) de forma que pueden hacer dos operaciones de forma simult√°nea (el formato est√°ndar es FP32) y adem√°s con la reducci√≥n de memoria (punto muy importante) al meter en los 32 bits 2 datos en lugar de s√≥lo uno. Tambi√©n se han a√±adido t√©cnicas de Mixed Precision (Narang et al. 2018), los Tensor Cores (para las gr√°ficas de NVIDIA) son otra de las mejoras que se han ido incorporando a la GPUs y que permiten acelerar los procesos tanto de entrenamiento como de predicci√≥n con las redes neuronales.

El primer objetivo ser√° convertir las variables categ√≥ricas en variables num√©ricas, de forma que el AE pueda trabajar con ellas. Para realizar la conversi√≥n de categ√≥rica a num√©rica b√°sicamente tenemos dos m√©todos para realizarlo: ‚Ä¢ Codificaci√≥n one-hot. ‚Ä¢ Codificaci√≥n entera. La codificaci√≥n one-hot consiste en crear tantas variables como categor√≠as tenga la variable, de forma que se asigna el valor 1 si tiene esa categor√≠a y el 0 si no la tiene.

La codificaci√≥n entera lo que hace es codificar con un n√∫mero cada categor√≠a. Realmente esta asignaci√≥n no tiene ninguna interpretaci√≥n num√©rica ya que en general las categor√≠as no tienen porque representar un orden al que asociarlas. Normalmente se trabaja con codificaci√≥n one-hot para representar los datos categ√≥ricos de forma que ser√° necesario preprocesar los datos de partida para realizar esta conversi√≥n, creando tantas variables como categor√≠as haya por cada variable. Si nosotros tenemos nuestra muestra de datos de que tiene variables de forma que , y son variables categ√≥ricas que tienen n√∫mero de categor√≠as respectivamente, tendremos finalmente las siguientes variables s√≥lo num√©ricas:

De esta forma, se aumentar√°n el n√∫mero de variables con las que vamos a trabajar en funci√≥n de las categor√≠as que tengan las variables categ√≥ricas. Normalmente nos encontramos que en una red neuronal las variables de salida son: ‚Ä¢ un n√∫mero (regresi√≥n) ‚Ä¢ una serie de n√∫meros (regresi√≥n m√∫ltiple) ‚Ä¢ un dato binario (clasificaci√≥n binaria) ‚Ä¢ una serie de datos binarios que representa una categor√≠a de varias (clasifiaci√≥n m√∫ltiple)

**Arquitectura de red**

Para la construcci√≥n de una red neuronal necesitamos definir la arquitectura de esa red. Esta arquitectura, si estamos pensando en una red neuronal densamente conectada, estar√° definida por la cantidad de capas ocultas y el n√∫mero de neuronas que tenemos en cada capa. M√°s adelante veremos que dependiendo del tipo de red neuronal podr√° haber otro tipo de elementos en estas capas. Funci√≥n de coste y p√©rdida Otro de los elementos clave que tenemos que tener en cuenta a la hora de usar nuestra red neuronal son las funciones de p√©rdida y funciones de coste (objetivo). La funci√≥n de p√©rdida va a ser la fuci√≥n que nos dice c√≥mo de diferente es el resultado del dato que nosotros quer√≠amos conseguir respecto al dato original. Normalmente se suelen usar diferentes tipos de funciones de p√©rdida en funci√≥n del tipo de resultado con el que se vaya a trabajar. La funci√≥n de coste es la funci√≥n que vamos a tener que optimizar para conseguir el m√≠nimo valor posible, y que recoge el valor de la funci√≥n de p√©rdida para toda la muestra. Tanto las funciones de p√©rdida como las funciones de coste, son funciones que devuelven valores de .

Si tenemos un problema de regresi√≥n en el que tenemos que predecir un valor o varios valores num√©ricos, algunas de las funciones a usar son: ‚Ä¢ Error medio cuadr√°tico () \[120\] , es el valor real e es el valor predicho ‚Ä¢ Error medio absoluto () \[121\] , es el valor real e es el valor predicho Para los problemas de clasifiaci√≥n: ‚Ä¢ Binary Crossentropy (S√≥lo hay dos clases) \[122\] es el valor real e es el valor predicho ‚Ä¢ Categorical Crosentropy (M√∫ltiples clases representadas como one-hot) \[123\] es el valor real para la clase e es el valor predicho para la clase ‚Ä¢ Sparse Categorical Crossentropy (M√∫ltiples clases representadas como un entero) \[124\] es el valor real para la clase e es el valor predicho para la clase ‚Ä¢ Kullback-Leibler Divergence Esta funci√≥n se usa para calcular la diferencia entre dos distribuciones de probabilidad y se usa por ejemplo en algunas redes como Variational Autoencoders (Doersch 2016) o Modelos GAN (Generative Adversarial Networks) \[125\] \[126\] \[127\] ‚Ä¢ Hinge Loss \[128\] Las correspondientes funciones de coste que se usar√≠an, estar√≠an asociadas a todas las muestras que se est√©n entrenando o sus correpondientes batch, as√≠ como posibles t√©rminos asociados a la regularizaci√≥n para evitar el sobreajuste del entrenamiento. Es decir, la funci√≥n de p√©rdida se calcula para cada muestra, y la funci√≥n de coste es la media de todas las muestras. Por ejemplo, para el Error medio cuadr√°tico () tendr√≠amos el siguiente valor: \[129\]

**Optimizador**

El Descenso del gradiente es la versi√≥n m√°s b√°sica de los algoritmos que permiten el aprendizaje en la red neuronal haciendo el proceso de backpropagation (propagaci√≥n hacia atr√°s). A continuaci√≥n veremos una breve explicaci√≥n del algoritmo as√≠ como algunas variantes del mismo recogidas en (Ruder 2017) Recordamos que el descenso del gradiente nos permitir√° actualizar los par√°metros de la red neuronal cada vez que demos una pasada hacia delante con todos los datos de entrada, volviendo con una pasada hacia atr√°s. \[130\] donde es la funci√≥n de coste, es el par√°metro de ratio de aprendizaje que permite definir como de grandes se quiere que sean los pasos en el aprendizaje. Cuando lo que hacemos es actualizar los par√°metros para cada pasada hacia delante de una sola muestra, estaremos ante lo que llamamos Stochastic Gradient Descent (SGD). En este proceso converger√° en menos iteraciones, aunque puede tener alta varianza en los par√°metros. \[131\] donde e son los valores en la pasada de la muestra . Podemos buscar un punto intermedio que ser√≠a cuando trabajamos por lotes y cogemos un bloque de datos de la muestra, les aplicamos la pasada hacia delante y aprendemos los par√°metros para ese bloque. En este caso lo llamaremos Mini-batch Gradient Descent \[132\] donde son los valores de ese batch . En general a estos m√©todos nos referiremos a ellos como SGD. Sobre este algoritmo base se han hecho ciertas mejoras como: **Learning rate decay** Podemos definir un valor de decenso del ratio de aprendizaje, de forma que normalmente al inicio de las iteraciones de la red neuronal los pasos ser√°n m√°s grandes, pero conforme nos acercamos a la soluci√≥n optima deberemos dar pasos m√°s peque√±os para ajustarnos mejor. \[133\] donde ahora se ir√° reduciendo en funci√≥n del valor del decay Momentum El **momentum** se introdujo para suavizar la convergencia y reducir la alta varianza de SGD. \[134\] \[135\] donde es lo que se llama el vector velocidad con la direcci√≥n correcta. **NAG (Nesterov Accelerated Gradient)** Ahora daremos un paso m√°s con el NAG, calculando la funci√≥n de coste junto con el vector velocidad. \[136\] \[137\] donde ahora vemos que la funci√≥n de coste se calcula usando los par√°metros de sumado a

Veamos algunos algoritmos de optimizaci√≥n m√°s que, aunque provienen del SGD, se consideran independientes a la hora de usarlos y no como par√°metros extras del SGD. **Adagrad (Adaptive Gradient)** Esta variante del algoritmo lo que hace es adaptar el ratio de aprendizaje para cada uno de los pesos en lugar de que sea global para todos. \[138\] donde tenemos que es una matriz diagonal donde cada elemento es la suma de los cuadrados de los gradientes en el paso , y es un t√©rmino de suavizado par evitar divisiones por 0.

**RMSEProp (Root Mean Square Propagation)** En este caso tenemos una variaci√≥n del Adagrad en el que intenta reducir su agresividad reduciendo monotonamente el ratio de aprendizaje. En lugar de usar el gradiente acumulado desde el principio de la ejecuci√≥n, se restringe a una ventana de tama√±o fijo para los √∫ltimos n gradientes calculando su media. As√≠ calcularemos primero la media en ejecuci√≥n de los cuadros de los gradientes como: \[139\] y luego ya pasaremos a usar este valor en la actualizaci√≥n \[140\]

**AdaDelta**

Aunque se desarrollaron de forma simult√°nea el AdaDelta y el RMSProp son muy parecidos en su primer paso incial, llegando el de AdaDelta un poco m√°s lejos en su desarrollo. \[141\] y luego ya pasaremos a usar este valor en la actualizaci√≥n \[142\] \[143\] **Adam (Adaptive Moment Estimation)** \[144\] \[145\] \[146\] donde y son estimaciones del primer y segundo momento de los gradientes respectivamente, y y par√°metros a asignar. \[147\] \[148\] \[149\] **Adamax** \[150\] \[151\] \[152\] \[153\] donde y son estimaciones del primer y segundo momento de los gradientes respectivamente, y y par√°metros a asignar. \[154\] \[155\] **Nadam (Nesterov-accelerated Adaptive Moment Estimatio)** Combina Adam y NAG. \[156\] \[157\] \[158\]

**Funci√≥n de activaci√≥n** Las funciones de activaci√≥n dentro de una red neuronal son uno de los elementos clave en el dise√±o de la misma. Cada tipo de funci√≥n de activaci√≥n podr√° ayudar a la convergencia de forma m√°s o menos r√°pida en funci√≥n del tipo de problema que se plantee. En un AE las funciones de activaci√≥n en las capas ocultas van a conseguir establecer las restricciones no lineales al pasar de una capa a la siguiente, normalmente se evita usar la funci√≥n de activaci√≥n lineal en las capas intermedias ya que queremos conseguir transformaciones no lineales. A continuaci√≥n, exponemos las principales funciones de activaci√≥n que mejores resultados dan en las capas ocultas: ‚Ä¢ Paso binario (Usado por los primeros modelos de neuronas) \[159\] ‚Ä¢ Identidad \[160\] ‚Ä¢ Sigmoid (Log√≠stica) \[161\] ‚Ä¢ Tangente Hiperb√≥lica (Tanh) \[162\] ‚Ä¢ Softmax \[163\]

```         
‚Ä¢ ReLu ( Rectified Linear Unit)
    [164]

‚Ä¢ LReLU (Leaky Rectified Linear Unit)
    [165]
‚Ä¢ PReLU (Parametric Rectified Linear Unit)
    [166]
‚Ä¢ RReLU (Randomized Rectified Linear Unit)
    [167]
```

\*La diferencia entre LReLu, PReLu y RRLeLu es que en LReLu el par√°metro es uno que se asigna fijo, en el caso de PReLu el par√°metro tambi√©n se aprende durante el entrenamiento y finalmente en RReLu es un par√°metro con valores entre 0 y 1, que se obtiene de un muestreo en una distribuci√≥n normal. Se puede profundizar en este grupo de funciones de activaci√≥n en (Xu et al. 2015) ‚Ä¢ ELU (Exponential Linear Unit) \[168\] FIGURA n¬∫ 64: COMPARACI√ìN ENTRE LAS FUNCIONES ReLU, LReLU/PReLU, RReLU y ELU

FUENTE: Jiuxiang, G. et al (2019)

**Funci√≥n de activaci√≥n en salida** En la capa de salida tenemos que tener en cuenta cual es el tipo de datos final que queremos obtener, y en funci√≥n de eso elegiremos cual es la funci√≥n de activaci√≥n de salida que usaremos. Normalmente las funciones de activaci√≥n que se usar√°n en la √∫ltima capa seran: ‚Ä¢ Lineal con una unidad, para regresi√≥n de un solo dato num√©rico \[169\] donde es un valor escalar. ‚Ä¢ Lineal con multiples unidades, para regresi√≥n de varios datos num√©ricos \[170\] donde es un vector. ‚Ä¢ Sigmoid para clasifiaci√≥n binaria \[171\] ‚Ä¢ Softmax para calsifiaci√≥n m√∫ltiple \[172\]

**Regularizaci√≥n** Las t√©cnicas de regularizaci√≥n nos permiten conseguir mejorar los problemas que tengamos por sobreajuste en el entrenamiento de nuestra red neuronal. A continuaci√≥n, vemos algunas de las t√©cnicas de regularizaci√≥n existentes en la actualidad: ‚Ä¢ Norma LP B√°sicamente estos m√©todos tratan de hacer que los pesos de las neuronas tengan valores muy peque√±os consiguiendo una distribuci√≥n de pesos m√°s regular. Esto lo consiguen al a√±adir a la funci√≥n de p√©rdida un coste asociado a tener pesos grandes en las neuronas. Este peso se puede construir o bien con la norma L1 (proporcional al valor absoluto) o con la norma L2 (proporcional al cuadrado de los coeficientes de los pesos). En general se define la norma LP) \[173\] \[174\] Para los casos m√°s habituales tendr√≠amos la norma L1 y L2. \[175\] \[176\]

**Dropout** Una de las t√©cnicas de regularizaci√≥n que m√°s se est√°n usando actualmente es la llamada Dropout, su proceso es muy sencillo y consiste en que en cada iteraci√≥n de forma aleatoria se dejan de usar un porcentaje de las neuronas de esa capa, de esta forma es m√°s dificil conseguir un sobreajuste porque las neuronas no son capaces de memorizar parte de los datos de entrada. **Dropconnect** El Dropconnect es otra t√©cnica que va un poco m√°s all√° del concepto de Dropout y en lugar de usar en cada capa de forma aleatoria una serie de neuronas, lo que se hace es que de forma aleatoria se ponen los pesos de la capa a cero. Es decir, lo que hacemos es que hay ciertos enlaces de alguna neurona de entrada con alguna de salida que no se activan.

**Inicializaci√≥n de pesos**

Cuando empieza el entrenamiento de una red neuronal y tiene que realizar la primera pasada hacia delante de los datos, necesitamos que la red neuronal ya tenga asignados alg√∫n valor a los pesos. Se pueden hacer inicializaciones del tipo: ‚Ä¢ Ceros Todos los pesos se inicializan a 0. ‚Ä¢ Unos Todos los pesos se inicializan a 1. ‚Ä¢ Distribuci√≥n normal Los pesos se inicializan con una distribuci√≥n normal, normalmente con media 0 y una desviaci√≥n alrededor de 0,05. Es decir, valores bastante cercanos al cero. ‚Ä¢ Distribuci√≥n normal truncada Los pesos se inicializan con una distribuci√≥n normal, normalmente con media 0 y una desviaci√≥n alrededor de 0,05 y adem√°s se truncan con un m√°ximo del doble de la desviaci√≥n. Los valores aun s√≥n m√°s cercanos a cero. ‚Ä¢ Distribuci√≥n uniforme Los pesos se inicializan con una distribuci√≥n uniforme, normalmente entre el 0 y el 1. ‚Ä¢ Glorot Normal (Tambi√©n llamada Xavier normal) Los pesos se inicializan partiendo de una distribuci√≥n normal truncada en la que la desivaci√≥n es donde es el n√∫mero de unidades de entrada y fanout es el n√∫mero de unidades de salida. Ver (Glorot and Bengio 2010) ‚Ä¢ Glorot Uniforme (Tambi√©n llamada Xavier uniforme) Los pesos se inicializan partiendo de una distribuci√≥n uniforme done los l√≠mites son done y es el n√∫mero de unidades de entrada y fanout es el n√∫mero de unidades de salida. Ver (Glorot and Bengio 2010)

**Batch normalization** Hemos comentado que cuando entrenamos una red neuronal los datos de entrada deben ser todos de tipo num√©rico y adem√°s los normalizamos para tener valores "cercanos a cero", teniendo una media de 0 y varianza de 1, consiguiendo uniformizar todas las variables y conseguir que la red pueda converger m√°s f√°cilmente. Cuando los datos entran a la red neuronal y se comienza a operar con ellos, se convierten en nuevos valores que han perdido esa propiedad de normalizaci√≥n. Lo que hacemos con la normalizaci√≥n por lotes (batch normalization) (Ioffe and Szegedy 2015) es que a√±adimos un paso extra para normalizar las salidas de las funciones de activaci√≥n. Lo normal es que se aplicara la normalizaci√≥n con la media y la varianza de todo el bloque de entrenamiento en ese paso, pero normalmente estaremos trabajando por lotes y se calcular√° la media y varianza con ese lote de datos.

### Principales arquitecturas de Deep Learning

Actualmente existen muchos tipos de estructuras de redes neuronales artificiales dado que logran resultados extraordinarios en muchos campos del conocimiento. Los primeros √©xitos en el aprendizaje profundo se lograron a trav√©s de las investigaciones y trabajos de Geoffre Hinton (2006) que introduce las Redes de Creencia Profunda en cada capa de la red de una M√°quina de Boltzmann Restringida (RBM) para la asignaci√≥n inicial de los pesos sin√°pticos. Hace tiempo que se est√° trabajando con arquitecturas como los Autoencoders, Hinton y Zemel (1994), las RBMs de Hinton y Sejnowski (1986) y las DBNs (Deep Belief Networks), Hinton et al. (2006) y otras como las redes recurrentes y convolucionales. Estas t√©cnicas constituyen en s√≠ mismas arquitecturas de redes neuronales, aunque tambi√©n algunas de ellas, como se ha afirmado en la introducci√≥n, se est√°n empleando para inicializar los pesos de arquitecturas profundas de redes neuronales supervisadas con conexiones hacia adelante. Las principales arquitecturas de deep learning se resumen en la siguiente figura. Figura 65. modelos de redes neuronales seg√∫n tipo de aprendizaje

Vamos a describir de forma somera las principales arquitecturas dado que posteriormente se desarrollan m√°s ampliamente en este ep√≠grafe o se tratan en docuemento adjunto que se acompa√±a en este m√≥dulo **Convolutional Neural Network** Tal vez los modelos m√°s utilizados actualmente en el campo del Deep Learning sean las redes neuronales convolucionales, denominadas en ingl√©s Convolutional Neural Networks (CNN). El objetivo de las redes CNN es aprender caracter√≠sticas de orden superior utilizando la operaci√≥n de convoluci√≥n. Estas estructuras de redes neuronales son especialmente eficaces para clasificar y segmentar im√°genes, en general, son notablemente eficaces en tareas de visi√≥n artificial. Las CNN son una modificaci√≥n del perceptr√≥n multicapa explicado en un m√≥dulo anterior. Este modelo es muy similar al trabajo que ejecuta el cerebro humano: las neuronas se corresponden a campos receptivos similares a como lo realizan las neuronas en la corteza visual de nuestro cerebro. Esta arquitectura ya se utiliz√≥ en 1990 donde la empresa AT & T las aplic√≥ para crear un modelo de lectura de cheques, desarroll√°ndose posteriormente muchos sistemas OCR basados en CNN. Las redes de convoluci√≥n tienen una estructura de varias capas: las capas de Convoluci√≥n que transforman los datos de entrada a trav√©s de una operaci√≥n matem√°tica llamada Convoluci√≥n y la capa de pooling, que trata de sintetizar y condensar la informaci√≥n de la capa de convoluci√≥n. Finalmente, se transforman los datos para aplicar una red densamente conectada que nos ofrece el resultado final en relaci√≥n con el objetivo que se busca. Estas redes neuronales artificiales se desarrollaron al abrigo de los concursos denominados ILSVRC (Large Scale Visual Recognition Challenge) donde aparecieron las principales aportaciones efectuadas en las redes convolucionales y que hoy podemos utilizar todos los investigadores. Algunos de las estructuras m√°s novedosas y que son modelos ya preentrenados, con estructuras de capas m√°s numerosas y que podemos integrar en nuestras aplicaciones, se denominan: LeNet-5, AlexNet, VGG, GoogLeNet y Resnet.

**Autoencoder** Los Autoencoders (AE) son uno de los tipos de redes neuronales que caen dentro del √°mbito del Deep Learning, en la que nos encontramos con un modelo de aprendizaje no supervisado. Ya se empez√≥ a hablar de AE en la d√©cada de los 80 (Bourlard and Kamp 1988), aunque es en estos √∫ltimos a√±os donde m√°s se est√° trabajando con ellos. La arquitectura de un AE es una Red Neuronal Artificial (ANN por sus siglas en ingl√©s) que se encuentra dividida en dos partes, encoder y decoder (Charte et al. 2018), (Goodfellow, Bengio, and Courville 2016). El encoder va a ser la parte de la ANN que va codificar o comprimir los datos de entrada, y el decoder ser√° el encargado de regenerar de nuevo los datos en la salida. Esta estructura de codificaci√≥n y decodificaci√≥n le llevar√° a tener una estructura sim√©trica. El AE es entrenado para ser capaz de reconstruir los datos de entrada en la capa de salida de la ANN, implementando una serie de restricciones (la reducci√≥n de elementos en las capas ocultas del encoder) que van a evitar que simplemente se copie la entrada en la salida. Algunas de sus principales aplicaciones sobre las que se est√° investigando son: ‚Ä¢ Reducci√≥n de dimensiones / Compresi√≥n de datos ‚Ä¢ B√∫squeda de im√°genes ‚Ä¢ Detecci√≥n de Anomal√≠as ‚Ä¢ Eliminaci√≥n de ruido **Redes recurrentes** En la actualidad las **redes neuronales recurrentes (Recurrent Neural Networks)** han logrado un puesto destacado en machine learning. Estas redes que no disponen de una estructura de capas, sino que permiten conexiones arbitrarias entre todas las neuronas, incluso creando ciclos. En esta arquitectura se permiten conexiones recurrentes lo que aumenta el n√∫mero de pesos o de par√°metros ajustables de la red, lo que incrementa la capacidad de representaci√≥n, pero tambi√©n la complejidad del aprendizaje. Las peculiaridades de esta red permiten incorporar a la red el concepto de temporalidad, y tambi√©n que la red tenga memoria, porque los n√∫meros que introducimos en un momento dado en las neuronas de entrada son transformados, y contin√∫an circulando por la red. Existen diferentes planteamientos de redes recurrentes, por ejemplo, son muy populares por sus aplicaciones las redes de Elmann y de Jordan. En los √∫ltimos a√±os se han popularizado las redes recurrentes denominadas Long-Short Term Memory (LSTM) que son una extension de las redes recurrentes y su caracter√≠tica principal es que amplian su memoria para registrar experiencias que han ocurrido hace mucho tiempo. Normalmente contienen tres puertas que determinan si se permite o no una nueva entrada o se elimina la informaci√≥n que llega dado que se considera no importante. Son an√°logas a una funci√≥n sigmoide lo que implica que van de 0 a 1, lo que permite incorporarlas al proceso de backpropagation. Tambi√©n se encuentran entre las redes recurrentes, las denominadas GRU (Gated Recurrent Unit) que aparecieron en 2014 y simplifican a las LSMT: son computacionalmente menos costosas y m√°s eficientes.

Boltzmann Machine y Restricted Boltzmann Machine El aprendizaje de la denominada m√°quina de Boltzmann (BM) se realiza a trav√©s de un algoritmo estoc√°stico que proviene de ideas basadas en la mec√°nica estad√≠stica. Este prototipo de red neuronal tiene una caracter√≠stica distintiva y es que el uso de conexiones sin√°pticas entre las neuronas es sim√©trico. Las neuronas son de dos tipos: visibles y ocultas. Las neuronas visibles son las que interact√∫an y proveen una interface entre la red y el ambiente en el que operan, mientras que las neuronas act√∫an libremente sin interacciones con el entorno. Esta m√°quina dispone de dos modos de operaci√≥n. El primero es la condici√≥n de anclaje donde las neuronas est√°n fijas por los est√≠mulos espec√≠ficos que impone el ambiente. El otro modo es la condici√≥n de libertad, donde tanto las neuronas ocultas como las visibles act√∫an libremente sin condiciones impuestas por el medio ambiente. Las maquinas restringidas de Boltzmann (RBM) solamente toman en cuenta aquellos modelos en los que no existen conexiones del tipo visible-visible y oculta-oculta. Estas redes tambi√©n asumen que los datos de entrenamiento son independientes y est√°n id√©nticamente distribuidos. Una forma de estimar los par√°metros de un modelo estoc√°stico es calculando la m√°xima verosimilitud. Para ello, se hace uso de los Markov Random Fiels (MRF), ya que al encontrar los par√°metros que maximizan los datos de entrenamiento bajo una distribuci√≥n MRF, equivale a encontrar los par√°metros ùúÉ que maximizan la verosimilitud de los datos de entrenamiento, Fischer e Igel (2012). Maximizar dicha verosimilitud es el objetivo que persigue el algoritmo de entrenamiento de una RBM. A pesar de utilizar la distribuci√≥n MRF, computacionalmente hablando se llega a ecuaciones inviables de implementar. Para evitar el problema anterior, las esperanzas que se obtienen de MRF pueden ser aproximadas por muestras extra√≠das de distribuciones basadas en las t√©cnicas de Markov Chain Monte Carlo Techniques (MCMC). Las t√©cnicas de MCMC utilizan un algoritmo denominado muestreo de Gibbs con el que obtenemos una secuencia de observaciones o muestras que se aproximan a partir de una distribuci√≥n de verosimilitud de m√∫ltiples variables aleatorias. La idea b√°sica del muestreo de Gibss es actualizar cada variable posteriormente en base a su distribuci√≥n condicional dado el estado de las otras variables. Deep Belief Network Una red Deep Belief Network tal como demostr√≥ Hinton se puede considerar como un "apilamiento de redes restringidas de Boltzmann". Tiene una estructura jer√°rquica que como sabemos es una de las caracter√≠sticas del deep learning. Como en el anterior modelo, esta red tambi√©n es un modelo en grafo estoc√°stico, que aprende a extraer una representaci√≥n jer√°rquica profunda de los datos de entrenamiento. Cada capa de la RBM extrae un nivel de abstracci√≥n de caracter√≠sticas de los datos de entrenamiento, cada vez m√°s significativo; pero para ello, la capa siguiente necesita la informaci√≥n de la capa anterior lo que implica el uso de las variables latentes. Estos modelos caracterizan la distribuci√≥n conjunta hk entre el vector de observaciones x y las capas ocultas, donde x=h0, es una distribuci√≥n condicional para las unidades visibles limitadas sobre las unidades ocultas que pertenecen a la RBM en el nivel k, y es la distribuci√≥n conjunta oculta visible en la red RBM del nivel superior o de salida. El entrenamiento de esta red puede ser h√≠brido, empezando por un entrenamiento no supervisado para despu√©s aplicar un entrenamiento supervisado para un mejor y m√°s √≥ptimo ajuste, aunque pueden aplicarse diferentes tipos de entrenamiento, Bengio et al. (2007) y Salakhutdinov (2014) Para realizar un entrenamiento no supervisado se aplica a las redes de creencia profunda con Redes restringidas de Boltzmann el m√©todo de bloque constructor que fue presentado por Hinton (2006) y por Bengio (2007)

## Redes Neuronales Convolucionales

### Introducci√≥n

Esta arquitectura de redes de neuronas convolucionales, CNN, Convolutional Neural Networks es en la actualidad el campo de investigaci√≥n m√°s fecundo dentro de las redes neuronales artificiales de Deep learning y donde los investigadores, empresas e instituciones est√°n dedicando m√°s recursos e investigaci√≥n. Para apoyar esta aseveraci√≥n, en google trend se observa que el t√©rmino convolutional neural network en relaci√≥n con el concepto de artificial neural network crece y est√° por encima desde el a√±o 2016. Es en este √∫ltimo lustro donde el Deep learning ha tomado una importancia considerable.

![b√∫squeda de t√©rminos de redes neuronales en google trend](imagenes/capitulo1/busqueda_google.png){#fig-busqueda-google}

Fuente: Google Trend En este modelo de redes convolucionales las neuronas se corresponden a campos receptivos similares a las neuronas en la corteza visual de un cerebro humano. Este tipo de redes se han mostrado muy efectivas para tareas de detecci√≥n y categorizaci√≥n de objetos y en la clasificaci√≥n y segmentaci√≥n de im√°genes. Por ejemplo, estas redes en la d√©cada de 1990 las aplic√≥ AT & T para desarrollar un modelo para la lectura de cheques. Tambi√©n m√°s tarde se desarrollaron muchos sistemas OCR basados en CNN. En esta arquitectura cada neurona de una capa no recibe conexiones entrantes de todas las neuronas de la capa anterior, sino s√≥lo de algunas. Esta estrategia favorece que una neurona se especialice en una regi√≥n del conjunto de n√∫meros (p√≠xeles) de la capa anterior, lo que disminuye notablemente el n√∫mero de pesos y de operaciones a realizar. Lo m√°s normal es que neuronas consecutivas de una capa intermedia se especialicen en regiones solapadas de la capa anterior. Una forma intuitiva para entender c√≥mo trabajan estas redes neuronales es ver c√≥mo nos representamos y vemos las im√°genes. Para reconocer una cara primero tenemos que tener una imagen interna de lo que es una cara. Y a una imagen de una cara la reconocemos porque tiene nariz, boca, orejas, ojos, etc. Pero en muchas ocasiones una oreja est√° tapada por el pelo, es decir, los elementos de una cara se pueden ocultar de alguna manera. Antes de clasificarla, tenemos que saber la proporci√≥n y disposici√≥n y tambi√©n c√≥mo se relacionan la partes entre s√≠. Para saber si las partes de la cara se encuentran en una imagen tenemos que identificar previamente l√≠neas bordes, formas, texturas, relaci√≥n de tama√±o, etc√©tera. En una red convolucional, cada capa lo que va a ir aprendiendo son los diferentes niveles de abstracci√≥n de la imagen inicial. Para comprender mejor el concepto anterior hemos seleccionado esta imagen de Raschka y Mirjalili (2019) donde se observa como partes del perro se transforman en neuronas del mapa de caracter√≠sticas

![Correspondencia de zonas de la imagen y mapa de caracter√≠sticas](imagenes/capitulo1/correspondencia_featrures.png){#fig-correspondencia-features}

Fuente: Raschka y Mirjalili (2019)

El objetivo de las redes CNN es aprender caracter√≠sticas de orden superior utilizando la operaci√≥n de convoluci√≥n. Puesto que las redes neuronales convolucionales pueden aprender relaciones de entrada-salida (donde la entrada es una imagen), en la convoluci√≥n, cada pixel de salida es una combinaci√≥n lineal de los pixeles de entrada. La convoluci√≥n consiste en filtrar una imagen utilizando una m√°scara. Diferentes m√°scaras producen distintos resultados. Las m√°scaras representan las conexiones entre neuronas de capas anteriores. Estas capas aprenden progresivamente las caracter√≠sticas de orden superior de la entrada sin procesar. Las redes neuronales convolucionales se forman usando dos tipos de capas: convolucionales y pooling. La capa de convoluci√≥n transforma los datos de entrada a trav√©s de una operaci√≥n matem√°tica llamada convoluci√≥n. Esta operaci√≥n describe c√≥mo fusionar dos conjuntos de informaci√≥n diferentes. A esta operaci√≥n se le suele aplicar una funci√≥n de transformaci√≥n, generalmente la RELU. Despu√©s de la capa o capas de convoluci√≥n se usa una capa de pooling, cuya funci√≥n es resumir las respuestas de las salidas cercanas. Antes de obtener el output unimos la √∫ltima capa de pooling con una red densamente conectada. Previamente se ha aplanado (Flatering) la √∫ltima capa de pooling para obtener un vector de entrada a la red neural final que nos ofrecer√° los resultados.

![Arquitectura de una CNN](imagenes/capitulo1/arquitectura_convolucional.png){#fig-arquitectura_convolucional}

Las redes neuronales convolucionales debido a su forma de concebirse son aptas para poder aprender a clasificar todo tipo de datos donde √©stos est√©n distribuidos de una forma continua a lo largo del mapa de entrada, y a su vez sean estad√≠sticamente similares en cualquier lugar del mapa de entrada. Por esta raz√≥n, son especialmente eficaces para clasificar im√°genes. Tambi√©n pueden ser aplicadas para la clasificaci√≥n de series de tiempo o se√±ales de audio. En relaci√≥n con el color y la forma de codificarse, en las redes convolucionales se realiza en tensores 3D, dos ejes para el ancho (width) y el alto (height) y el otro eje llamado de profundidad (depht) que es el canal del color con valor tres si trabajamos con im√°genes de color RGB (Red, Green y Blue) rojo, verde y azul. Si disponemos de im√°genes en escala de grises el valor de depht es uno. La base de datos MNIST (National Institute of Standards and Technology database) con la que trabajaremos en este ep√≠grafe contiene im√°genes de 28 x 28 pixeles, los valores de height y de widht son ambos 28, y al ser una base de datos en blanco y negro el valor de depht es 1. Las im√°genes son matrices de p√≠xeles que van de cero a 255 y que para la red neuronal se normalizan para que sus valores oscilen entre cero y uno. 7.4.2. Convoluci√≥n En las redes convolucionales todas las neuronas de la capa de entrada (los p√≠xeles de las im√°genes) no se conectan con todas las neuronas de la capa oculta del primer nivel como lo hacen las redes cl√°sicas del tipo perceptr√≥n multicapa o las redes que conocemos de forma gen√©rica como redes densamente conectadas. Las conexiones se realizan por peque√±as zonas de la capa de entrada.

![Conexi√≥n de las neuronas de la capa de entrada con la capa oculta](imagenes/capitulo1/conexion_neuronas_convolucional.png){#fig-conexion-neuronas-convolucional}

Veamos un ejemplo para la base de datos de los d√≠gitos del 1 a 9. Vamos a conectar cada neurona de la capa oculta con una regi√≥n de 5 x 5 neurona, es decir, con 25 neuronas de la capa de entrada, que podemos denominarla ventana. Esta ventana va a ir recorriendo todo el espacio de entrada de 28 x 28 empezando por arriba y desplaz√°ndose de izquierda a derecha y de arriba abajo. Suponemos que los desplazamientos de la ventana son de un paso (un pixel) aunque este es un par√°metro de la red que podemos modificar (en la programaci√≥n lo llamaremos stride). Para conectar la capa de entrada con la de salida utilizaremos una matriz de pesos (W) de tama√±o 3 x 3 que recibe el nombre de filtro (filter) y el valor del sesgo. Para obtener el valor de cada neurona de la capa oculta realizaremos el producto escalar entre el filtro y la ventana de la capa de entrada. Utilizamos el mismo filtro para obtener todas las neuronas de la capa oculta, es decir en todos los productos escalares siempre utilizamos la misma matriz, el mismo filtro. Se definen matem√°ticamente estos productos escalares a trav√©s de la siguiente expresi√≥n: \[177\]

Como en este tipo de red un filtro s√≥lo nos permite revelar una caracter√≠stica muy concreta de la imagen, lo que se propone es usar varios filtros simult√°neamente, uno para cada caracter√≠stica que queramos detectar. Una forma visual de representarlo (si suponemos que queremos aplicar 32 filtros) es como se muestra a continuaci√≥n:

![Primera capa de la red convolucional con 32 filtros](imagenes/capitulo1/primera_capa_convolucional.png){#fig-primera-capa-convolucional}

Al resultado de la aplicaci√≥n de los diferentes filtros se les suele aplicar la funci√≥n de activaci√≥n denominada RELU y que ya se coment√≥ en la introducci√≥n. Una interesante fuente de informaci√≥n es la documentaci√≥n del software gratuito GIMP donde expone diferentes efectos que se producen en las im√°genes al aplicar diversas convoluciones. Un ejmplo claro y did√°ctico lo podemos obtener de la docuemntaci√≥n del software libre de dibujo y tratamiento de im√°genes denominado GIMP (https://docs.gimp.org/2.6/es/plug-in-convmatrix.html). Algunos de estos efectos nos ayudan a entender la operaci√≥n de los filtros en las redes convolucionales y c√≥mo afectan a las im√°genes, en concreto, el ejemplo que presenta lo realiza sobre la figura del Taj Mahal El filtro enfocar lo que consigue es afinar los rasgos, los contornos lo que nos permite agudizar los objetos de la imagen. Toma el valor central de la matriz de cinco por cinco lo multiplica por cinco y le resta el valor de los cuatro vecinos. Al final hace una media, lo que mejora la resoluci√≥n del pixel central porque elimina el ruido o perturbaciones que tiene de sus pixeles vecinos. El filtro enfocar (Sharpen)

Lo contario al filtro enfocar lo obtenemos a trav√©s de la matriz siguiente, difuminando la imagen al ser estos p√≠xeles mezclados o combinados con los pixeles cercanos. Promedia todos los p√≠xeles vecinos a un pixel dado lo que implica que se obtienen bordes borrosos. Filtro desenfocar

Filtro Detectar bordes (Edge Detect) Este efecto se consigue mejorando los l√≠mites o las aristas de la imagen. En cada p√≠xel se elimina su vecino inmediatamente anterior en horizontal y en vertical. Se eliminan las similitudes vecinas y quedan los bordes resaltados. Al pixel central se le suman los cuatro p√≠xeles vecinos y lo que queda al final es una medida de c√≥mo de diferente es un p√≠xel frente a sus vecinos. En el ejemplo, al hacer esto da un valor de cero de ah√≠ que se observen tantas zonas oscuras.

Filtro Repujado (Emboss) En este filto se observa que la matriz es sim√©trica y lo que intenta a trav√©s del dise√±o del filtro es mejorar los p√≠xeles centrales y de derecha abajo rest√°ndole los anteriores. Se obtiene lo que en fotograf√≠a se conoce como un claro oscuro. Trata de mejorar las partes que tienen mayor relevancia.

### Pooling

Con la operaci√≥n de pooling se trata de condensar la informaci√≥n de la capa convolucional. A este procedimiento tambi√©n se le conoce como submuestreo. Es simplemente una operaci√≥n en la que reducimos los par√°metros de la red. Se aplica normalmente a trav√©s de dos operaciones: max-pooling y mean-pooling, que tambi√©n es conocido como average-pooling. Tal y como se observa en la imagen siguiente, desde la capa de convoluci√≥n se genera una nueva capa aplicando la operaci√≥n a todas las agrupaciones, donde previamente hemos elegido el tama√±o de la regi√≥n; en la figura siguiente es de tama√±o 2, con lo que pasamos de un espacio de 24 x 24 neuronas a la mitad, 12 x 12 en la capa de pooling.

Figura 71. etapa de pooling de tama√±o 2 x 2

![etapa de pooling de tama√±o 2 x 2](imagenes/capitulo1/pooling.png){#fig-pooling}

Vamos a estudiar el pooling suponiendo que tenemos una imagen de 5 x 5 p√≠xeles y que queremos efectuar una agrupaci√≥n max-pooling. Es la m√°s utilizada, ya que obtiene buenos resultados. Observamos los valores de la matriz y se escoge el valor m√°ximo de los cuatro bloques de matrices de dos por dos. Max Pooling

En la agrupaci√≥n Average Pooling la operaci√≥n que se realiza es sustituir los valores de cada grupo de entrada por su valor medio. Esta transformaci√≥n es menos utilizada que el max-pooling.

La transformaci√≥n max-pooling presenta un tipo de invarianza local: peque√±os cambios en una regi√≥n local no var√≠an el resultado final realizado con el max -- pooling: se mantiene la relaci√≥n espacial. Para ilustrar este concepto hemos escogido la imagen que presenta Torres (2020) donde se ilustra como partiendo de una matriz de 12 x 12 que representa al n√∫mero 7, al aplicar la operaci√≥n de max-pooling con una ventana de 2 x 2 se conserva la relaci√≥n espacial.

![Max Pooling](imagenes/capitulo1/max_pooling.png){#fig-max-pooling}

![Average Pooling](imagenes/capitulo1/average_pooling.png){#fig-average-pooling}

Fuente: Torres. J. (2020)

### Padding

Para explicar el concepto del Padding vamos a suponer que tenemos una imagen de 5 x 5 p√≠xeles, es decir 25 neuronas en la capa de entrada, y que elegimos, para realizar la convoluci√≥n, una ventana de 3 x 3. El n√∫mero de neuronas de la capa oculta resultar√° ser de nueve. Enumeramos los p√≠xeles de la imagen de forma natural del 1 al 25 para que resulte m√°s sencillo de entender.

![mantenimiento del pooling con la transformaci√≥n](imagenes/capitulo1/transformacion_pooling.png){#fig-transformacion-pooling}

Pero si queremos obtener un tensor de salida que tenga las mismas dimensiones que la entrada podemos rellenar la matriz de ceros antes de deslizar la ventana por ella. Vemos la figura siguiente donde ya se ha rellenado de valores cero y obtenemos, despu√©s de deslizar la ventana de 3 x3 de izquierda a derecha y de arriba abajo, las veinticinco matrices de la figura n¬∫ 71

![Operaci√≥n de convoluci√≥n con una ventana de 3 x 3](imagenes/capitulo1/sin_padding.png){#fig-sin-padding}

Figura n¬∫ 74. imagen con relleno de ceros

![Imagen con relleno de ceros](imagenes/capitulo1/relleno_ceros.png){#fig-relleno-ceros}

Cuando utilizamos el programa keras disponemos de dos opciones para llevar a cabo esta operaci√≥n de padding: "same" y "valid". Si utilizamos "valid" implica no hacer padding y el m√©todo "same" obliga a que la salida tenga la misma dimensi√≥n que la entrada.

![Operaci√≥n de convoluci√≥n con ventana 3 x 3 y padding](imagenes/capitulo1/con_padding.png){#fig-con-padding}

### Stride

Hasta ahora, la forma de recorrer la matriz a trav√©s de la ventana se realiza desplaz√°ndola de un solo paso, pero podemos cambiar este hiperpar√°metro conocido como stride. Al aumentar el paso se decrementa la informaci√≥n que pasar√° a la capa posterior. A continuaci√≥n, se muestra el resultado de las cuatro matrices que obtenemos con un stride de valor 3.

![Operaci√≥n de convoluci√≥n con una ventana de 3 x 3 y stride 2](imagenes/capitulo1/con_stride2.png){#fig-con-stride2}

Finalmente, para resumir, una red convolucional contiene los siguientes elementos: ‚Ä¢ Entrada: Son el n√∫mero de pixeles de la imagen. Ser√°n alto, ancho y profundidad. Tenemos un solo color (escala de grises) o tres: rojo, verde y azul. ‚Ä¢ Capa de convoluci√≥n: procesar√° la salida de neuronas que est√°n conectadas en ¬´regiones locales¬ª de entrada (es decir pixeles cercanos), calculando el producto escalar entre sus pesos (valor de pixel) y una peque√±a regi√≥n a la que est√°n conectados. En este ep√≠grafe se presentan las im√°genes con 32 filtros, pero puede realizarse con la cantidad que deseemos. ‚Ä¢ ¬´Capa RELU¬ª Se aplicar√° la funci√≥n de activaci√≥n en los elementos de la matriz. ‚Ä¢ POOL (agrupar) o Submuestreo: Se procede normalmente a una reducci√≥n en las dimensiones alto y ancho, pero se mantiene la profundidad. ‚Ä¢ CAPA tradicional. Se finalizar√° con la red de neuronas feedforward (Perceptr√≥n multicapa que se denomina normalmente como red densamente conectada) que vincular√° con la √∫ltima capa de subsampling y finalizar√° con la cantidad de neuronas que queremos clasificar. En el gr√°fico siguiente se muestran todas las fases de una red neuronal convolucional.

![Operaci√≥n de convoluci√≥n completa](imagenes/capitulo1/convolucion_completa.png){#fig-convolucion-completa} Fuente: Raschka y Mirjalili (2019)

### Redes convolucionales con nombre propio

Existen en la actualidad muchas arquitecturas de redes neuronales convolucionales que ya est√°n preparadas, probadas, disponibles e incorporadas en el software de muchos programas como Keras y Tensorflow. Vamos a comentar algunos de estos modelos, bien por ser los primeros, o por sus excelentes resultados en concursos como el ILSVRC (Large Scale Visual Recognition Challenge). Estas estructuras merecen atenci√≥n dado que son excelentes para estudiarlas e incorporarlas por su notable √©xito. El ILSVRC fue un concurso celebrado de 2011 a 2016 de donde nacieron las principales aportaciones efectuadas en las redes convolucionales. Este concurso fue dise√±ado para estimular la innovaci√≥n en el campo de la visi√≥n computacional. Actualmente se desarrollan este tipo de concursos a trav√©s de la plataforma web: https://www.kaggle.com/ Para ver m√°s prototipos de redes convolucionales y los √∫ltimos avances y consejos sobre las redes convolucionales se puede consultar el siguiente art√≠culo "Recent Advances in Convolutional Neural Networks" de Jiuxiang. G. et al. (2019) Los cinco modelos m√°s destacados hasta el a√±o 2017 son los siguientes: LeNet-5, Alexnet, GoogLeNet, VGG y Restnet. 1. LeNet-5. Este modelo de Yann LeCun de los a√±os 90 consigui√≥ excelentes resultados en la lectura de c√≥digos postales consta de im√°genes de entrada de 32 x 32 p√≠xeles seguida de dos etapas de convoluci√≥n -- pooling, una capa densamente conectada y una capa softmax final que nos permite conocer los n√∫meros o las im√°genes. 2. AlexNet. Fue la arquitectura estrella a partir del a√±o 2010 en el ILSVRC y popularizada en el documento de 2012 de Alex Krizhevsky, et al.¬†titulado"Clasificaci√≥n de ImageNet con redes neuronales convolucionales profundas". Podemos resumir los aspectos clave de la arquitectura relevantes en los modelos modernos de la siguiente manera: ‚Ä¢ Empleo de la funci√≥n de activaci√≥n ReLU despu√©s de capas convolucionales y softmax para la capa de salida. ‚Ä¢ Uso de la agrupaci√≥n m√°xima en lugar de la agrupaci√≥n media. ‚Ä¢ Utilizaci√≥n de la regularizaci√≥n de Dropout entre las capas totalmente conectadas. ‚Ä¢ Patr√≥n de capa convolucional alimentada directamente a otra capa convolucional. ‚Ä¢ Uso del aumento de datos (Data Aumentation,) 3. VGG. Este prototipo fue desarrollado por un grupo de investigaci√≥n de Geometr√≠a Visual en Oxford. Obtuvo el segundo puesto en la competici√≥n del a√±o 2014 del ILSVRC. Las aportaciones principales de la investigaci√≥n se pueden encontrar en el documento titulado "¬†Redes convolucionales muy profundas para el reconocimiento de im√°genes a gran escala¬†" desarrollado por Karen Simonyan y Andrew Zisserman. Este modelo contribuy√≥ a demostrar que la profundidad de la red es una componente cr√≠tica para alcanzar unos buenos resultados. Otra diferencia importante con los modelos anteriores y que actualmente es muy utilizada es el uso de un gran n√∫mero de filtros y de tama√±o reducido. Estas redes emplean ejemplos de dos, tres e incluso cuatro capas convolucionales apiladas antes de usar una capa de agrupaci√≥n m√°xima. En esta arquitectura el n√∫mero de filtros aumenta con la profundidad del modelo. El modelo comienza con 64 y aumenta a trav√©s de los filtros de 128, 256 y 512 al final de la parte de extracci√≥n de caracter√≠sticas del modelo. Los investigadores evaluaron varias variantes de la arquitectura si bien en los programas s√≥lo se hace referencia a dos de ellas que son las que aportan un mayor rendimiento y que son nombradas por las capas que tienen: VGG-16 y VGG-19. 4. GoogLeNet. GoogLeNet fue desarrolado por investigadores de Google Research. de Google, que con su m√≥dulo denominado de inception reduce dr√°sticamente los par√°metros de la red (10 veces menos que AlexNet) y de ella han derivado varias versiones como la Inception-v4. Esta arquitectura gan√≥ la competici√≥n en el a√±o 2014 y su √©xito se debi√≥ a que la red era mucho m√°s profunda (muchas m√°s capas) y como ya se ha indicado introdujeron en el modelo las subredes llamadas inception. Las aportaciones principales en el uso de capas convolucionales fueron propuestos en el documento de 2015 por Christian Szegedy, et al. titulado "¬†Profundizando con las convoluciones¬†". Estos autores introducen una arquitectura llamada "inicio" y un modelo espec√≠fico denominado GoogLenet. El m√≥dulo inicio es un bloque de capas convolucionales paralelas con filtros de diferentes tama√±os y una capa de agrupaci√≥n m√°xima de 3 √ó 3, cuyos resultados se concatenan. Otra decisi√≥n de dise√±o fundamental en el modelo inicial fue la conexi√≥n de la salida en diferentes puntos del modelo que lograron realizar con la creaci√≥n de peque√±as redes de salida desde la red principal y que fueron entrenadas para hacer una predicci√≥n. La intenci√≥n era proporcionar una se√±al de error adicional de la tarea de clasificaci√≥n en diferentes puntos del modelo profundo para abordar el problema de los gradientes de fuga. 5. Red Residual o ResNet. Esta arquitectura gano la competici√≥n de 2015 y fue creada por el grupo de investigaci√≥n de Microsoft. Se puede ampliar la informaci√≥n en He, et al. en su documento de 2016 titulado "¬†Aprendizaje profundo residual para el reconocimiento de la imagen¬†". Esta red es extremadamente profunda con 152 capas, confirmando al pasar los a√±os que las redes son cada vez m√°s profundas, m√°s capas, pero con menos par√°metros que estimar. La cuesti√≥n clave del dise√±o de esta red es la incorporaci√≥n de la idea de bloques residuales que hacen uso de conexiones directa. Un bloque residual, seg√∫n los autores, "es un patr√≥n de dos capas convolucionales con activaci√≥n ReLU donde la salida del bloque se combina con la entrada al bloque, por ejemplo, la conexi√≥n de acceso directo" Otra clave, en este caso para el entrenamiento de la red tan profunda es lo que llamaron skip connections que implica que la se√±al con la que se alimenta una capa tambi√©n se agregue a una capa que se encuentre m√°s adelante. Resumiendo, las tres principales aportaciones de este modelo son: ‚Ä¢ Empleo de conexiones de acceso directo. ‚Ä¢ Desarrollo y repetici√≥n de los bloques residuales. ‚Ä¢ Modelos muy profundos (152 capas) Aunque se encuentran otros modelos que tambi√©n son muy populares con 34, 50 y 101 capas. Una buena parte de los modelos comentados se incluyen en la librer√≠a de Keras y se pueden encontrar en la siguiente direcci√≥n de internet: https://keras.io/api/applications/ Seg√∫n los autores del programa Keras: "Las aplicaciones Keras son modelos de aprendizaje profundo que est√°n disponibles junto con pesos preentrenados. Estos modelos se pueden usar para predicci√≥n, extracci√≥n de caracter√≠sticas y ajustes. Los pesos se descargan autom√°ticamente cuando se crea una instancia de un modelo. Se almacenan en \~ / .keras / models /. Tras la creaci√≥n de instancias, los modelos se construir√°n de acuerdo con el formato de datos de imagen establecido en su archivo de configuraci√≥n de Keras en \~ / .keras / keras.json. Por ejemplo, si ha configurado image_data_format = channel_last, cualquier modelo cargado desde este repositorio se construir√° de acuerdo con la convenci√≥n de formato de datos TensorFlow,"Altura-Ancho-Profundidad".

![Modelos preentrenados en Keras](imagenes/capitulo1/modelos_entrenados.png){#fig-modelos-entrenados} Fuente : https://keras.io/api/applications/

## Redes Nueronales Recurrentes

{{< redes_recurrentes.qmd >}}

## Autoencoders

**Bases del Autoencoder** Los Autoencoders (AE) son uno de los tipos de redes neuronales que caen dentro del √°mbito del Deep Learning, en la que nos encontramos con un modelo de aprendizaje no supervisado. Ya se empez√≥ a hablar de AE en la d√©cada de los 80 (Bourlard and Kamp 1988), aunque es en estos √∫ltimos a√±os donde m√°s se est√° trabajando con ellos. La arquitectura de un AE es una Red Neuronal Artificial (ANN por sus siglas en ingl√©s) que se encuentra dividida en dos partes, encoder y decoder (Charte et al. 2018), (Goodfellow, Bengio, and Courville 2016). El encoder va a ser la parte de la ANN que va codificar o comprimir los datos de entrada, y el decoder ser√° el encargado de regenerar de nuevo los datos en la salida. Esta estructura de codificaci√≥n y decodificaci√≥n le llevar√° a tener una estructura sim√©trica. El AE es entrenado para ser capaz de reconstruir los datos de entrada en la capa de salida de la ANN, implementando una serie de restricciones (la reducci√≥n de elementos en las capas ocultas del encoder) que van a evitar que simplemente se copie la entrada en la salida. Si recordamos la estructura de una ANN cl√°sica o tambi√©n llamada Red Neuronal Densamente Conectada (ya que cada neurona conecta con todas las de la siguiente capa) nos encontramos en que en esta arquitectura, generalmente, el n√∫mero de neuronas por capa se va reduciendo hasta llegar a la capa de salida que deber√≠a ser normalmente un n√∫mero (si estamos en un problema regresi√≥n), un dato binario (si es un problema de clasificaci√≥n). Figura n¬∫ 86: Red Neuronal Clasica

Fuente: Elaboraci√≥n propia Si pensamos en una estructura b√°sica de AE en la que tenemos una capa de entrada, una capa oculta y una capa de salida, √©sta ser√≠a su representaci√≥n:

Figura n¬∫ 87: Autoencoder b√°sico

Fuente: Elaboraci√≥n propia Donde los valores de son los datos de entrada y los datos son la reconstrucci√≥n de los mismos despu√©s de pasar por la capa oculta que tiene s√≥lo dos dimensiones. El objetivo del entrenamiento de un AE ser√° que estos valores de sean lo m√°s parecidos posibles a los . Seg√∫n (Charte et al. 2018) los AE se puden clasificar seg√∫n el tipo de arquitectura de red en: ‚Ä¢ Incompleto simple ‚Ä¢ Incompleto profundo ‚Ä¢ Extra dimensionado simple ‚Ä¢ Extra dimensionado profundo

Figura n¬∫ 88: Tipos de Autoencoders por arquitectura

Fuente: Elaboraci√≥n propia Cuando hablamos de Incompleto nos referimos a que tenemos una reducci√≥n de dimensiones que permite llegar a conseguir una "compresi√≥n" de los datos iniciales como t√©cnica para que aprenda los patrones internos. En el caso de Extra dimensionado es cuando subimos de dimensi√≥n para conseguir que aprenda esos patrones. En este √∫ltimo caso ser√≠a necesario aplicar t√©cnicas de regularizaci√≥n para evitar que haya un sobreajuste en el aprendizaje. Cuando hablamos de Simple estamos haciendo referencia a que hay una √∫nica capa oculta, y en el caso de Profundo es que contamos con m√°s de una capa oculta. Normalmente se trabaja con las arquitecturas de tipo Incompleto profundo, sobre todo cuando se est√° trabajando con tipos de datos que son im√°genes. Aunque tambi√©n podr√≠amos encontrar una combinaci√≥n de Incompleto con Extra dimensionado profundo cuando trabajamos con tipos de datos que no son im√°genes y as√≠ crecer en la primera o segunda capa oculta, para luego reducir. Esto nos permitir√≠a por ejemplo adaptarnos a estructuras de AE en las que trabajemos con n√∫mero de neuronas en una capa que sean potencia de 2, y poder construir arquitecturas din√°micas en funci√≥n del tama√±o de los datos, adapt√°ndolos a un tama√±o prefijado. A continuaci√≥n, vemos un gr√°fico de una estructura mixta Extra dimensionado - Incompleto profundo. Figura n¬∫ 89: Autoencoder Mixto (Incompleto y Extra dimensionado)

Fuente: Elaboraci√≥n propia Idea intuitiva del uso de Autoencoders Si un AE trata de reproducir los datos de entrada mediante un encoder y decoder, ¬øque nos puede aportar si ya tenemos los datos de entrada? Ya hemos comentado que la red neuronal de un AE es sim√©trica y est√° formada por un encoder y un decoder, adem√°s cuando trabajamos con los AE que son incompletos, se est√° produciendo una reducci√≥n del tama√±o de los datos en la fase de codificaci√≥n y de nuevo una regeneraci√≥n a partir de esos datos m√°s peque√±os al original. Ya tenemos uno de los conceptos m√°s importantes de los AE que es la reducci√≥n de dimensiones de los datos de entrada. Estas nuevas variables que se generan una vez pasado el encoder se les suele llamar el espacio lantente. Este concepto de reducci√≥n de dimensiones en el mundo de la miner√≠a de datos lo podemos asimiliar r√°pidamente a t√©cnicas como el An√°lisis de Componentes Principales (PCA), que nos permite trabajar con un n√∫mero m√°s reducido de dimensiones que las originales. Igualmente, esa reducci√≥n de los datos y la capacidad de poder reconstruir el original podemos asociarlo al concepto de compresi√≥n de datos, de forma que con el encoder podemos comprimir los datos y con el decoder los podemos descomprimir. En este caso habr√≠a que tener en cuenta que ser√≠a una t√©cnica de compresi√≥n de datos con p√©rdida de informaci√≥n (JPG tambi√©n es un formato de compresi√≥n con p√©rdida de compresi√≥n). Es decir, con los datos codificados y el AE (pesos de la red neuronal), ser√≠amos capaces de volver a regenerar los datos originales. Otra de las ideas alrededor de los AE es que, si nosotros tenemos un conjunto de datos de la misma naturaleza y los entrenamos con nuestro AE, somos capaces de construir una red neuronal (pesos en la red neuronal) que es capaz de reproducir esos datos a trav√©s del AE. Que ocurre si nosotros metemos un dato que no era de la misma naturaleza que los que entrenaron el AE, lo que tendremos entonces es que al recrear los datos originales no va a ser posible que se parezca a los datos de entrada. De forma que el error que vamos a tener va a ser mucho mayor por no ser datos de la misma naturaleza. Esto nos puede llevar a construir un AE que permita detectar anomal√≠as, es decir, que seamos capaces de detectar cuando un dato es una anomal√≠a porque realmente el AE no consigue tener un error lo bastante peque√±o. Seg√∫n lo visto de forma intuitiva vamos a tener el encoder que ser√° el encargado de codificar los datos de entrada y luego tendremos el decoder que ser√° el encargado de realizar la decodificaci√≥n y conseguir acercarnos al dato original . Es decir intentamos conseguir . Si suponemos un Simple Autoencoder en el que tenemos una √∫nica capa oculta, con una funci√≥n de activaci√≥n intermedia y una funci√≥n de activaci√≥n de salida y los par√°metros y represetan los par√°metros de la red neuronal en cada capa, tendr√≠amos la siguiente expresi√≥n: \[190\] \[191\]

As√≠ tendremos que donde ser√° la reconstrucci√≥n de Una vez tenemos la idea intuitiva de para qu√© nos puede ayudar un AE, recopilamos algunos de los principales usos sobre los que actualmente se est√° trabajando. M√°s adelante ,comentaremos algunos de ellos con m√°s detalle. Principales Usos de los Autoencoders A continuaci√≥n, veamos la explicaci√≥n de cuales son algunos de los principales usos de los autoencoders: Reducci√≥n de dimensiones / Compresi√≥n de datos En la idea intuitiva de los AE ya hemos visto claro que se pueden usar para la reducci√≥n de dimensiones de los datos de entrada. Si estamos ante unos datos de entrada de tipo estructurado estamos en un caso de reducci√≥n de dimensiones cl√°sico, en el que queremos disminuir el n√∫mero de variables con las que trabajar. Muchas veces este tipo de trabajo se hace mediante el PCA (An√°lisis de Componente Principales, por sus siglas en ingl√©s), sabiendo que lo que se realiza es una transformaci√≥n lineal de los datos, ya que conseguimos unas nuevas variables que son una combinaci√≥n lineal de las mismas. En el caso de los AE conseguimos mediante las funciones de activaci√≥n no lineales (simgmoide, ReLu, tanh, etc) combinaciones no lineales de las variables originales para reducir las dimensiones. Tambi√©n existen versiones de PCA no lineales llamadas Kernel PCA que mediante las t√©cnicas de kernel son capaces de construir relaciones no lineales. En esta l√≠nea estamos viendo que cuando el encoder ha actuado, tenemos unos nuevos datos m√°s reducidos y que somos capaces de practicamente volver a reproducir teniendo el decoder. Podr√≠amos pensar en este tipo de t√©cnica para simplemente comprimir informaci√≥n. Hay que tener en cuenta que este tipo de t√©cnicas no se pueden aplicar a cualquier dato que queramos comprimir, ya que debemos haber entrenado al AE con unos datos de entrenamiento que ha sido capaz de obtener ciertos patrones de ellos, y por eso es capaz luego de reproducirlos. B√∫squeda de im√°genes Cuando pensamos en un buscador de im√°genes nos podemos hacer a la idea que el buscar al igual que con el texto nos va a mostrar entradas que se√°n im√°genes parecidas a la que estamos buscando. Si construimos un autoencoder, el encoder nos va a dar unas variables con informaci√≥n para poder recrear de nuevo la imagen. Lo que parece claro es que si hay muy poca distancia entre estas variables y otras la reconstrucci√≥n de la imagen ser√° muy parecida. As√≠ nosotros podemos entrenar el AE con nuestro conjunto de im√°genes, una vez tenemos el AE pasamos el encoder a todas las im√°genes y las tenemos todas en ese nuevo espacio de variables. Cuando queremos buscar una imagen, le pasamos el autoencoder, y ya buscamos las m√°s cercanas a nuestra imagen en el espacio de variables generado por el encoder. Detecci√≥n de Anomal√≠as Cuando estamos ante un problema de clasificaci√≥n y tenemos un conjunto de datos que est√° muy desbalanceado, es decir, tenemos una clase mayoritaria que es mucho m√°s grande que la minoritaria (posiblemente del orden de m√°s del 95%), muchas veces es complicado conseguir un conjunto de datos balanceado que sea realmente bueno para hacer las predicciones. Cuando estamos en estos entornos tan desbalanceados muchas veces se dice que estamos ante un sistema para detectar anomal√≠as. Un AE nos puede ayudar a detectar estas anomal√≠as de la siguiente forma: ‚Ä¢ Tomamos todos los datos de entrenamiento de la clase mayoritaria (o normales) y construimos un AE para ser capaces de reproducirlos. Al ser todos estos datos de la misma naturaleza conseguiremos entrenar el AE con un error muy peque√±o. ‚Ä¢ Ahora tomamos los datos de la clase minoritaria (o a nomal√≠as) y los pasamos a trav√©s del AE obteniendo unos errores de reconstrucci√≥n. ‚Ä¢ Definimos el umbral de error que nos separar√° los datos normales de las anomal√≠as, ya que el AE s√≥lo est√° entrenado con los normales y conseguir√° un error m√°s alto con las anomal√≠as al reconstruirlas. ‚Ä¢ Cogemos los datos de test y los vamos pasando por el AE, si el error es menor del umbral, entonces ser√° de la clase mayoritaria. Si el error es mayor que el umbral, entonces estaremos ante una anomal√≠a. Eliminaci√≥n de ruido Otra de las formas de uso de los autoencoders en tratamiento de im√°genes es para eliminar ruido de las mismas, es decir poder quitar manchas de las im√°genes. La forma de hacer esto es la siguiente: ‚Ä¢ Partimos de un conjunto de datos de entrenamiento (im√°genes) a las que le metemos ruido, por ejemplo, modificando los valores de cada pixel usando una distribuci√≥n normal, de forma que obtenemos unos datos de entrenamiento con ruido. ‚Ä¢ Construimos el AE de forma que los datos de entrada son los que tienen ruido, pero los de salida vamos a forzar que sean los originales. De forma que intentamos que aprendan a reconstruirse como los que no tienen ruido. ‚Ä¢ Una vez que tenemos el AE y le pasamos datos de test con ruido, seremos capaces de reconstruirlos sin el ruido. Modelos generativos Cuando hablamos de modelos generativos, nos referimos a AE que son capaces de generar cosas nuevas a las que exist√≠an. De forma que mediante t√©cnicas como los Variational Autoencoders, los Adversarial Autoencoders seremos capaces de generar nuevas im√°genes que no ten√≠amos inicialmente. Es decir, podr√≠amos pensar en poder tener un AE que sea capaz de reconstruir im√°genes de caras, pero que adem√°s con toda la informaci√≥n aprendida fuera capaz de generar nuevas caras que realmente no existen. Dise√±o del modelo de AE Transformaci√≥n de datos Cuando se trabaja con redes neuronales y en particular con AEs, necesitamos representar los valores de las variables de entrada en forma num√©rica. En una red neuronal todos los datos son siempre num√©ricos. Esto significa que todas aquellas variables que sean categ√≥ricas necesitamos convertirlas en num√©ricas. Adem√°s es muy conveniente normalizar los datos para poder trabajar con valores entre 0 y 1, que van a ayudar a que sea m√°s f√°cil que se pueda converger a la soluci√≥n. Como ya sabemos normalmente nos encontramos que en una red neuronal las variables de salida son: ‚Ä¢ un n√∫mero (regresi√≥n) ‚Ä¢ una serie de n√∫meros (regresi√≥n m√∫ltiple) ‚Ä¢ un dato binario (clasificaci√≥n binaria) ‚Ä¢ un n√∫mero que representa una categor√≠a (clasifiaci√≥n m√∫ltiple) En el caso de los AE puede que tengamos una gran parte de las veces valores de series de n√∫meros, ya que necesitamos volver a representar los datos de entrada. Esto significa que tendremos que conseguir en la capa de salida esos datos num√©ricos que ten√≠amos inicialmente, como si se tuviera una regresi√≥n m√∫ltiple. Arquitectura de red Como ya se ha comentado en las redes neuronales, algunos de los hiperpar√°metros m√°s importantes en un AE son los relacionados con la arquitectura de la red neuronal. Para la construcci√≥n de un AE vamos a elegir una topolog√≠a sim√©trica del encoder y el decoder. Durante el dise√±o del AE necesitaremos ir probando y adaptando todos estos hiperpar√°metros de la ANN para conseguir que sea lo m√°s eficiente posible: ‚Ä¢ N√∫mero de capas ocultas y neuronas en cada una ‚Ä¢ Funci√≥n de coste y p√©rdida ‚Ä¢ Optimizador ‚Ä¢ Funci√≥n de activaci√≥n en capas ocultas ‚Ä¢ Funci√≥n de activaci√≥n en salida N√∫mero de capas ocultas y neuronas en cada una La selecci√≥n del n√∫mero de capas ocultas y la cantidad de neuronas en cada una va a ser un procedimiento de prueba y error en el que se pueden probar muchas combinaciones. Es cierto que en el caso de trabajar con im√°genes y CNN ya hay muchas arquitecturas definidas y probadas que consiguen muy buenos resultados. Por otro lado para tipos de datos estructurados ser√° muy dependiente de esos datos, de forma que ser√° necesario realizar diferentes pruebas para conseguir un buen resultado. Funci√≥n de coste y p√©rdida En este caso no hay ninguna recomendaci√≥n especial para las funciones de costes/p√©rdida y depender√° al igual que en las redes neuronales de la naturaleza de los datos de salida con los que vamos a trabajar. Optimizador Se recomienda usar el optimizador ADAM (Diederik P. Kingma 2017) que es el que mejores resultados ha dado en las pruebas seg√∫n (Walia 2017), consiguiendo una convergencia m√°s r√°pida que con el resto de optimizadores.

Funci√≥n de activaci√≥n en capas ocultas En un AE las funciones de activaci√≥n en las capas ocultas van a conseguir establecer las restricciones no lineales al pasar de una capa a la siguiente, normalmente se evita usar la funci√≥n de activaci√≥n lineal en las capas intermedias ya que queremos conseguir transformaciones no lineales. Se recomienda usar la funci√≥n de activaci√≥n ReLu en las capas ocultas, ya que parece ser que es la que mejores resultados da en la convergencia de la soluci√≥n y adem√°s menor coste computacional tiene a la hora de realizar los c√°lculos. Funci√≥n de activaci√≥n en salida En la capa de salida tenemos que tener en cuenta cual es el tipo de datos final que queremos obtener, que en el caso de un AE es el mismo que el tipo de dato de entrada. Normalmente las funciones de activaci√≥n que se usar√°n en la √∫ltima capa seran: ‚Ä¢ Lineal con multiples unidades, para regresi√≥n de varios datos num√©ricos ‚Ä¢ Sigmoid para valores entre 0 y 1 Tipos de Autoencoders Una vez entendido el funcionamiento de los AE, veamos algunos de los AE que se pueden construir para diversas tareas. ‚Ä¢ Simple ‚Ä¢ Multicapa o Profundo ‚Ä¢ Sparse ‚Ä¢ Convolucional ‚Ä¢ Denoising ‚Ä¢ Variational En la descripci√≥n de los tipos de AE vamos usar c√≥digo en R y en python y el framework keras con el backend Tensorflow. Todo el c√≥digo se proporciona aparte. Usaremos como dataset a MINIST, que contiene 60.000/10.000 (entrenamiento/validaci√≥n) im√°genes de los n√∫meros del 0 al 9, escritos a mano. Cada imagen tiene un tama√±o de 28x28 = 784 pixels, en escala de grises, con lo que para cada pixel tendremos un valor entre 0 y 255 para definir cu√°l es su intensidad de gris. Autoencoder Simple Vamos a describir como construir un autoencoder Simple usando una red neuronal densamente conectada en lugar de usar una red neuronal convolucional, para que sea m√°s sencillo comprender el ejemplo. Es decir, vamos a tratar los datos de entrada como si fueran unos datos num√©ricos que queremos reproducir y no vamos a utilizar ninguna de las t√©cnicas asociadas a las redes convolucionales. Hay que recordar que las redes convolucionales permiten mediante un tratamiento de las im√°genes (convoluci√≥n, pooling, etc) conseguir mejores resultados que si lo hici√©ramos directamente con redes densamente conectadas. En este caso tendremos una capa de entrada con 784 neuronas (correspondientes a los pixels de cada imagen), una capa intermedia de 32 neuronas, y una capa de salida de nuevo de las 784 neuronas para poder volver a obtener de nuevo los datos originales. En nuestro ejemplo vamos a tener los siguientes elementos. ‚Ä¢ 1 capa de entrada (784 datos), 1 capa oculta (32 datos) y una capa de salida (784 datos) ‚Ä¢ La funci√≥n de coste/p√©rdida va a ser la Entrop√≠a ‚Ä¢ Usaremos el optimizador Adam ‚Ä¢ Como funci√≥n activaci√≥n intermedia usaremos ReLu ‚Ä¢ Como funci√≥n activaci√≥n de salida sigmoid (ya que queremos un valor entre 0 y 1 ) Autoencoder Sparse Ya hemos comentado que una forma de conseguir que un autoencoder aprenda estructuras o correlaciones es la reducci√≥n del n√∫mero de neuronas, pero parte de este trabajo tambi√©n se puede conseguir mediante t√©cnicas de sparsing (escasez). Este tipo de t√©cnicas se usan normalmente en las ANN para evitar el sobreajuste de nuestro modelo, de forma que en cada actualizaci√≥n de los pesos de la red no se tienen en cuenta todas las neuronas de la capa. Es decir, vamos a conseguir que en las capas que decidamos no todas las neuronas van a estar activadas, de esta manera adem√°s de ayudar a evitar el sobreajuste, tambi√©n conseguiremos crear esas correlaciones que ayudan a construir el autoencoder. Existen dos metodos b√°sicos para generar el sparse que son: ‚Ä¢ Regularizaci√≥n L1 ‚Ä¢ Regularizaci√≥n L2 B√°sicamente los dos m√©todos tratan de hacer que los pesos de las neuronas tengan valores muy peque√±os consiguiendo una distribuci√≥n de pesos m√°s regular. Esto lo consiguen al a√±adir a la funci√≥n de p√©rdida un coste asociado a tener pesos grandes en las neuronas. Este peso se puede construir o bien con la norma L1 (proporcional al valor absoluto) o con la norma L2 (proporcional al cuadrado de los coeficientes de los pesos). B√°sicamente trabajaremos con un AE Simple, con una red densamente conectada, al que le aplicaremos la regularizaci√≥n en su capa oculta. En nuestro ejemplo vamos a tener los siguientes elementos. - 1 capa de entrada, 1 capaa oculta y una capa de salida - Las capas ocultas tendr√°n aplicada la Regularizaci√≥n L2 - La funci√≥n de coste/p√©rdida va a ser la Entrop√≠a - Usaremos el optimizador Adam - Como funci√≥n activaci√≥n intermedia usaremos ReLu - Como funci√≥n activaci√≥n de salida sigmoid (ya que queremos un valor entre 0 y 1) Autoencoder Multicapa o profundo Vamos a pasar ahora a una versi√≥n del autoencoder donde habilitamos m√°s capas ocultas y hacemos que el descenso del n√∫mero de neuronas sea m√°s gradual hasta llegar a nuestro valor deseado, para luego volver a reconstruirlo. En este caso seguimos con redes densamente conectadas y aplicamos varias capas intermedias reduciendo el n√∫mero de neuronas en cada una hasta llegar a la capa donde acaba el encoder para volver a ir creciendo en las sucesivas capas hasta llegar a la de salida. En nuestro ejemplo vamos a tener los siguientes elementos. - 1 capa de entrada (784 datos), 5 capa ocultas (32 datos intermedia) y una capa de salida (784 datos) - La funci√≥n de coste/p√©rdida va a ser la Entrop√≠a - Usaremos el optimizador Adam - Como funci√≥n activaci√≥n intermedia usaremos ReLu - Como funci√≥n activaci√≥n de salida sigmoid (ya que queremos un valor entre 0 y 1) Autoencoder Convolucional En nuestro ejemplo al estar trabajando con im√°genes podemos pasar a trabajar con Redes Convolucionales (CNN) de forma que en lugar de usar las capas densamente conectadas que hemos usado hasta ahora, vamos a pasar a usar las capacidades de las redes convolucionales. Al trabajar con redes convolucionales necesitaremos trabajar con capas de convoluci√≥n o pooling para llegar a la capa donde acaba el encoder para volver a ir creciendo aplicando operaciones de convoluci√≥n y upsampling (contrario al pooling). En nuestro ejemplo vamos a tener los siguientes elementos. - 1 capa de entrada, 5 capas ocultas y una capa de salida - La funci√≥n de coste/p√©rdida va a ser la Entrop√≠a - Usaremos el optimizador Adam - Como funci√≥n activaci√≥n intermedia usaremos ReLu - Como funci√≥n activaci√≥n de salida sigmoid (ya que queremos un valor entre 0 y 1) Autoencoder Denoising Vamos a usar ahora un autoencoder para hacer limpieza en imagen, es decir, conseguir a partir de una imagen que tiene ruido otra imagen sin ese ruido. Entrenaremos al autoencoder para que limpie "ruido" que hay en la imagen y lo reconstruya sin ello. El ruido lo vamos a generar mediante una distribuci√≥n normal y modificaremos el valor de los pixels de las im√°genes. Usaremos estas im√°genes con ruido para que sea capaz de reconstruir la imagen original sin ruido con el AE. Para realizar este proceso lo que haremos ser√°\_ ‚Ä¢ Crear nuevas im√°genes con ruido ‚Ä¢ Entrenar el autoencoder con estas nuevas im√°genes ‚Ä¢ Calcular el error de reconstrucci√≥n respecto a las im√°genes originales Al estar trabajando con im√°genes vamos a partir del Autoencoder de Convoluci√≥n para poder aplicar el denosing. En nuestro ejemplo vamos a tener los siguientes elementos. - 1 capa de entrada, 5 capas ocultas y una capa de salida - La funci√≥n de coste/p√©rdida va a ser la Entrop√≠a - Usaremos el optimizador Adam - Como funci√≥n activaci√≥n intermedia usaremos ReLu - Como funci√≥n activaci√≥n de salida sigmoid (ya que queremos un valor entre 0 y 1) Autoencoder Variational Los Variational Autoencoder son un tipo de modelo que se denomina generativo, ya que va a permitir construir nuevas im√°genes que no exist√≠an a partir de otras imagenes con las que se ha entrenado a la red neuronal. En realidad, es un autoencoder que durante el entrenamiento se le regulariza para evitar un sobreajuste y asegurar que en el espacio latente (intermedio) tenga buenas propiedades que permitan un buen proceso generativo. El proceso de construir este tipo de AE es muy parecido a los que ya hemos visto, con una peque√±a diferencia en el paso entre el proceso de encoder y el posterior decoder. Hasta ahora lo que ten√≠amos era que lo que obten√≠amos del encoder se lo pas√°bamos directamente al decoder, en este caso, el resultado del encoder no va a ser realmente un dato, sino una distribuci√≥n de datos. De forma que al decoder no se le pasa directamente lo que ha salido del encoder, si no otro elemento cogido de la distribuci√≥n generada. En este caso el proceso ser√≠a: ‚Ä¢ Se codifica la entrada con el encoder no como un dato concreto, sino como una distribuci√≥n normal (media y desviaci√≥n) ‚Ä¢ Se toma una muestra de un punto del espacio latente a partir de la distribuci√≥n ‚Ä¢ Se decodifica el punto de muestra con el decoder ‚Ä¢ Se calcula la funci√≥n de p√©rdida con el error de reconstrucci√≥n y la parte de regularizaci√≥n ‚Ä¢ Se usa el backpropagation a trav√©s de la red neuronal para ajustar los pesos Figura n¬∫ 90: Autoencoder Mixto (Incompleto y Extra dimensionado)

Fuente: https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73 Una vez que tenemos entrenado nuestro autoencoder seremos capaces de construir nuevas im√°genes partiendo de puntos que est√©n en la distribuci√≥n del espacio latente, de forma que esas peque√±as variaciones van a dar lugar a im√°genes finales diferentes.


## Arquiecturas Preentranadas

### Detecci√≥n de objetos
### Tratamiento de audios
### Tareas sobre textos

## Aprendizaje por Refuerzo
{{< include reinforcement_learning.qmd >}}


## Redes Generativas Adversarias


## Actualidad y algunos conceptos relacionados con el Deep Learning

## Software para aplicar Deep Learning
