{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df2d6a67-e6b5-4d5a-9cd9-3b8caa837589",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# USO LLMS PARA ANALIZAR TEXTOS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02c9c2b4-746c-4a3e-9519-a9cd8c8d99f1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Ejemplos de uso\n",
    "- Obtención términos relevantes en el texto\n",
    "- Resumen del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdfd7c9e-5202-4bc0-93c5-a7699f98c588",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Monitor] stop monitoring\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from loguru import logger\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b07a7d66-bb0d-41d0-8201-3e9ce5d13fb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = \"/dbfs/FileStore/70822317g@santalucia.es/real_madrid_gana_liga.csv\"\n",
    "spanish_league_text = pd.read_csv(path)[\"texto\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d40cab3-931a-4602-8e2b-ad33020bf3aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _call_llm_model(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Función que llama al modelo LLM para hacer una predicción a partir de un prompt\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Mensaje del prompt\n",
    "\n",
    "    Returns:\n",
    "        response (str): Respuesta del modelo si no hay fallo en la conexión.\n",
    "        En otro caso, devuelve el mensaje de error\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = get_deploy_client(\"databricks\")\n",
    "        response = client.predict(\n",
    "            endpoint=\"paa-gpt-4o-v20240513-dedicado-analitica\",\n",
    "            inputs={\"messages\": [{\"role\": \"user\", \"content\": prompt}]}\n",
    "        )\n",
    "        response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        logger.info(\"Ejecución del LLM realizada\")\n",
    "    except HTTPError as e:\n",
    "        if e.response.text:\n",
    "            logger.info(f\"{e}. Response text: {e.response.text}\")\n",
    "        else:\n",
    "            logger.info(e)\n",
    "        response = e\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "529d0000-1e67-4ede-95e9-0fe022878a72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _add_business_question_prompt(prompt: str, business_question: str) -> str:\n",
    "  \"\"\"\n",
    "  Función que añade al prompt la cuestión de negocio\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Mensaje del prompt\n",
    "        business_question (str): Pregunta de negocio a clasificar\n",
    "\n",
    "    Returns:\n",
    "        response (str): Respuesta del modelo si no hay fallo en la conexión.\n",
    "        En otro caso, devuelve el mensaje de error\n",
    "  \"\"\"\n",
    "  prompt_end = \" \".join(prompt)\n",
    "  prompt_end = prompt_end.replace(\"{business_question}\", business_question)\n",
    "  return prompt_end\n",
    "\n",
    "def _extraer_lista(text: str) -> list:\n",
    "  \"\"\"\n",
    "  Función que extrae la lista del texto respuesta proporcionado por el LLM\n",
    "\n",
    "  Args:\n",
    "      text (str): Texto respuesta del LLM\n",
    "\n",
    "  Returns:\n",
    "      response (str): Respuesta del modelo si no hay fallo en la conexión.\n",
    "      En otro caso, devuelve el mensaje de error\n",
    "  \"\"\"\n",
    "  # Usar expresiones regulares para encontrar el contenido entre corchetes\n",
    "  patron = re.search(r'\\[.*\\]', text, re.DOTALL)\n",
    "  \n",
    "  if patron:\n",
    "    # Convertir el contenido de la lista de cadena a lista de Python\n",
    "    output = ast.literal_eval(patron.group(0))\n",
    "  else:\n",
    "    output = []\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f8fcae7-d96a-40a1-b5fb-ac3a3c5eeb97",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ejemplo 1\n",
    "\n",
    "Definimos el prompt con las instrucciones adecuadas:\n",
    "- Obtener una lista de términos relevantes del texto\n",
    "- Incluye ejemplo para ayudar a que el LLM aprenda a realizar la operación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a219300-295e-4536-b186-a58c741bd440",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_1 = [\n",
    "  \"SYSTEM: Eres un asistente que analiza un texto y extrae los términos más relevantes y que definan el contenido del texto\\n\\n\",\n",
    "  \"USER: A partir del siguiente texto: '{business_question}'\\n\\n\",\n",
    "  \"extra en una lista los 10 términos más importanes que caractericen el texto. Que la lista sea en formato python\"\n",
    "  \"INSTRUCTIONS: \\n\\n\",\n",
    "  \"1. Presta atención al texto y devuelve los términos en formato lista de términos: [term1, term2, term3]\\n\\n\"\n",
    "  \"Ejemplo de uso\\n\\n\"\n",
    "  \"Pregunta: Soy Pablo Sánchez Cabrera, profesor del máster de la Uned de Big Data Science y data scientist en Santalucía. Me gusta el fútbol y la literatura. Quiero mostrar a los alumnos del curso un ejemplo típico de uso de LLMs\\n\\n\",\n",
    "  \"Respuesta: [Pablo Sánchez Cabrera, profesor, Uned, Big Data Science, Santalucía, futbol, literatura, alumnos, LLMs, ejemplo]\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc5e2077-a9ec-4c33-92cb-576f0904bd39",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-28 20:24:23.168\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_call_llm_model\u001B[0m:\u001B[36m19\u001B[0m - \u001B[1mEjecución del LLM realizada\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Real Madrid',\n",
       " 'Liga',\n",
       " 'Carlo Ancelotti',\n",
       " 'Barcelona',\n",
       " 'campeones',\n",
       " 'Tebas',\n",
       " 'negligencia arbitral',\n",
       " 'lesiones',\n",
       " 'temporada 2023-2024',\n",
       " 'Jude Bellingham']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_end = _add_business_question_prompt(prompt_1, spanish_league_text)\n",
    "list_of_terms = _call_llm_model(prompt_end)\n",
    "_extraer_lista(list_of_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be980105-4c11-44a1-906a-28c8a3a75ef0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Ejemplo 2\n",
    "\n",
    "\n",
    "Definimos el prompt con las instrucciones adecuadas:\n",
    "- Resume el texto que se proporciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3e1877f-14cb-4a8c-8ace-4aa0fbb5a68f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prompt_2 = [\n",
    "  \"SYSTEM: Eres un asistente que analiza un texto y hace un resumen del mismo\\n\\n\",\n",
    "  \"USER: A partir del siguiente texto: '{business_question}' resume dicho texto entre 50-100 palabras\"\n",
    "  \"INSTRUCTIONS: \\n\\n\",\n",
    "  \"Presta atención al texto y haz un breve resumen. No incluyas más de 100 palabras\\n\\n\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f74cadff-0631-481a-94ee-78d730a4fa8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2024-06-28 20:24:25.269\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_call_llm_model\u001B[0m:\u001B[36m19\u001B[0m - \u001B[1mEjecución del LLM realizada\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'El Real Madrid ha ganado su 36ª Liga tras vencer al Cádiz y aprovechando el empate del Barcelona. El autor celebra este logro, reservando críticas para los árbitros, la Federación Española de Fútbol, y acusando al Barcelona de corrupción en años anteriores. Recalca las dificultades superadas por el equipo, como lesiones importantes y decisiones arbitrales controversiales, y elogia el trabajo de Carlo Ancelotti y el rendimiento de jugadores como Jude Bellingham y Lucas Vázquez. Destaca que, a pesar de las adversidades, el Real Madrid ha sido implacable y dominante en la competición, mereciendo plenamente el título.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_end = _add_business_question_prompt(prompt_2, spanish_league_text)\n",
    "_call_llm_model(prompt_end)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "uned_speech2text_extracción_terminos_relevantes",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
