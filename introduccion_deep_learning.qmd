## Introducción

El **deep learning**, también conocido como aprendizaje **profundo**, es una disciplina que busca emular el funcionamiento del cerebro mediante el uso de hardware y software, generando inteligencia artificial. Este enfoque se materializa en redes neuronales artificiales (RNA), que emplean una abstracción jerárquica para representar datos en múltiples niveles. El proceso implica la utilización de arquitecturas de varias capas, donde cada una aprende patrones más complejos, favoreciendo el aprendizaje útil. Generalmente, se emplea aprendizaje no supervisado para guiar el entrenamiento de las capas intermedias. Aunque derivado del machine learning, el deep learning se distingue por su arquitectura en capas, inCluyendo redes convolucionales y recurrentes, en contraste con métodos más simples como el Perceptrón Multicapa de una sola capa. Su avance se vio inicialmente obstaculizado por problemas de estancamiento en mínimos locales, resueltos mediante preentrenamiento no supervisado de las capas. Este enfoque ha impulsado un rápido crecimiento en el desarrollo de arquitecturas y algoritmos de RNA en los últimos años, manteniendo la esencia del aprendizaje jerárquico y profundo.

Las redes neuronales tienen una amplia gama de aplicaciones en diversos campos, desde la clasificación y regresión de datos hasta la identificación de imágenes, texto y audio.

En la *identificación de imágenes*, por ejemplo, pueden reconocer animales, señales de tráfico, frutas, caras humanas e incluso tumores malignos en radiografías. A medida que se combinan estas capacidades, se pueden abordar problemas más complejos como la detección de objetos y personas en imágenes o el etiquetado de escenas. Con el *análisis de videos*, las redes neuronales pueden contar personas, reconocer objetos y señales de tráfico, o detectar comportamientos como llevar un arma.

Cuando se trata de *datos de texto*, las redes neuronales se utilizan en sistemas de traducción, chatbots y conversión de texto a audio. En el caso de *datos de audio*, se emplean en sistemas de traducción, altavoces inteligentes y conversión de audio a texto.

Para **trabajar con redes neuronales**, es crucial representar los datos de entrada numéricamente, incluso convirtiendo variables categóricas en valores numéricos y normalizando los datos entre 0 y 1. Esto facilita la convergencia hacia soluciones óptimas. Es importante que los datos seán números en coma flotante, sobre todo si se van a trabajar con *GPUs, Graphics Process Units*, ya que permitirán hacer un mejor uso de los multiples cores que les permiten operar en coma flotante de forma paralela. Actualmente, hay toda una serie de mejoras en las GPUs que permite aumentar el rendimiento de las redes neuronales como son el uso de operaciones en *FP16* (Floating Point de 16 bits en lugar de 32) de forma que pueden hacer dos operaciones de forma simultánea (el formato estándar es FP32) y además con la reducción de memoria (punto muy importante) al meter en los 32 bits 2 datos en lugar de sólo uno. También se han añadido técnicas de *Mixed Precision* (Narang et al. 2018), los *Tensor Cores* (para las gráficas de NVIDIA) son otra de las mejoras que se han ido incorporando a la GPUs y que permiten acelerar los procesos tanto de entrenamiento como de predicción con las redes neuronales.
